<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Part 4: Attention</title>
    <meta name="theme-color" content="#0A0A0F"/>
    <meta name="description" content="Transform an RNN-based model into a GPT-2 style transformer. Learn about attention mechanisms, layer normalization, and transformer blocks using plain JavaScript." />
    <style>
        :root{
            --bg:#0a0a0f;
            --bg-2:#0e0e16;
            --panel:#12121c;
            --panel-2:#171726;
            --text:#e9e9f2;
            --muted:#a5a7bf;
            --line:#1e1e2e;
            --pink:#ff2e88;
            --pink-2:#ff86c3;
            --glow: 0 0 .5rem var(--pink), 0 0 1.25rem color-mix(in oklab, var(--pink) 70%, white 0%), 0 0 2.5rem color-mix(in oklab, var(--pink) 35%, black 65%);
            --radius:16px;
            --pad: clamp(14px, 1.6vw, 22px);
            --font: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, "Helvetica Neue", Arial, "Noto Sans", "Liberation Sans", "Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol";
            --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
        }

        *{box-sizing:border-box}
        html,body{min-height:100%}
        body{
            margin:0;
            font-family:var(--font);
            color:var(--text);
            background:
                radial-gradient(1200px 520px at 50% -160px, rgba(255,46,136,.12), transparent 75%),
                linear-gradient(180deg, #090914 0%, #050509 45%, #030306 75%, #020203 100%);
            background-color:#020203;
            background-repeat:no-repeat, no-repeat;
            background-size:130% 70%, 100% 100%;
            background-position:center top, center top;
            background-attachment: fixed;
            line-height:1.6;
            overflow-x:hidden;
            -webkit-font-smoothing:antialiased;
            -moz-osx-font-smoothing:grayscale;
        }

        /* Subtle scanlines for retro vibe */
        body::before{
            content:"";
            position:fixed; inset:0;
            pointer-events:none;
            background-image: linear-gradient(rgba(255,255,255,.03),rgba(255,255,255,0) 2px);
            background-size:100% 3px; mix-blend-mode:overlay; opacity:.25;
        }
        @media (prefers-reduced-motion: reduce){
            body::before{display:none}
            *{animation: none !important; transition: none !important}
        }

        .container{width:min(1000px, 92vw); margin-inline:auto}

        /* Header */
        header{
            background: linear-gradient(180deg, #131321, #11111c);
            border-bottom: 1px solid var(--line);
            padding: 1.5rem 0;
            position: sticky;
            top: 0;
            z-index: 10;
            backdrop-filter: blur(10px);
        }

        nav{
            display: flex;
            align-items: center;
            justify-content: space-between;
            gap: 1rem;
        }

        .logo{
            font-weight: 900;
            font-size: 1.25rem;
            color: var(--text);
            text-decoration: none;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .logo .pink{
            color: var(--pink);
            text-shadow: var(--glow);
        }

        .back-btn{
            appearance:none;
            border:1px solid color-mix(in oklab, var(--pink) 35%, #ffffff00 65%);
            color:var(--text);
            background: linear-gradient(180deg, var(--panel) 0%, var(--panel-2) 100%);
            padding:.45rem .85rem;
            border-radius: 999px;
            cursor:pointer;
            font-weight:600;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 0.35rem;
            font-size: 0.9rem;
            transition: transform .12s ease, box-shadow .15s ease;
        }

        .back-btn:hover{
            box-shadow: var(--glow);
            transform: translateY(-1px);
        }

        /* Article Hero */
        .article-hero{
            padding: 3rem 0 2rem;
            position: relative;
        }

        .grid-bg{
            position:absolute; inset:0; pointer-events:none; z-index:-1; opacity:.25;
            background:
                radial-gradient(circle at 50% -60px, color-mix(in oklab, var(--pink) 30%, transparent), transparent 35%),
                repeating-linear-gradient(0deg, #ffffff10 0 1px, transparent 1px 36px),
                repeating-linear-gradient(90deg, #ffffff10 0 1px, transparent 1px 36px);
            mask: radial-gradient(1200px 600px at 50% 0, black 40%, transparent 80%);
        }

        h1{
            font-size: clamp(32px, 5vw, 48px);
            line-height: 1.1;
            font-weight: 900;
            margin-bottom: 1rem;
            background: linear-gradient(135deg, var(--text) 0%, var(--pink) 100%);
            -webkit-background-clip: text;
            background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .article-meta{
            display: flex;
            flex-wrap: wrap;
            gap: 1.5rem;
            color: var(--muted);
            font-size: 0.9rem;
            margin-bottom: 1rem;
        }

        .article-meta span{
            display: flex;
            align-items: center;
            gap: 0.35rem;
        }

        .article-blurb{
            font-size: 1.125rem;
            line-height: 1.6;
            color: #d9d9ec;
            max-width: 800px;
        }

        /* Article Content */
        article{
            background: linear-gradient(180deg, #131321, #11111c);
            border: 1px solid #222238;
            border-radius: var(--radius);
            padding: 2.5rem;
            margin: 2rem 0 3rem;
            box-shadow: 0 18px 50px rgba(0,0,0,.45), 0 0 60px -10px rgba(255,46,136,.15);
        }

        article h1{
            color: var(--text);
            margin: 2.5rem 0 1rem 0;
            font-size: 2.25rem;
            font-weight: 900;
            position: relative;
            padding-bottom: 0.75rem;
            background: none;
            -webkit-text-fill-color: var(--text);
        }

        article h1::after{
            content: "";
            position: absolute;
            bottom: 0;
            left: 0;
            width: 80px;
            height: 3px;
            background: linear-gradient(90deg, var(--pink), transparent);
        }

        article h1:first-child{
            margin-top: 0;
        }

        article h2{
            color: var(--text);
            margin: 2.5rem 0 1rem 0;
            font-size: 1.875rem;
            font-weight: 800;
            position: relative;
            padding-bottom: 0.75rem;
        }

        article h2::after{
            content: "";
            position: absolute;
            bottom: 0;
            left: 0;
            width: 60px;
            height: 2px;
            background: linear-gradient(90deg, var(--pink), transparent);
        }

        article h2:first-child{
            margin-top: 0;
        }

        article h3{
            color: var(--text);
            margin: 2rem 0 1rem 0;
            font-size: 1.375rem;
            font-weight: 700;
        }

        article h4{
            color: var(--text);
            margin: 1.5rem 0 0.75rem 0;
            font-size: 1.125rem;
            font-weight: 600;
        }

        article p{
            margin-bottom: 1.25rem;
            color: #d9d9ec;
            line-height: 1.7;
        }

        article ul, article ol{
            margin: 1.25rem 0;
            padding-left: 1.75rem;
            color: #d9d9ec;
        }

        article li{
            margin-bottom: 0.5rem;
            line-height: 1.7;
        }

        article strong{
            color: var(--text);
            font-weight: 600;
        }

        /* Links within article content */
        article a{
            color: var(--pink-2);
            text-decoration: none;
            border-bottom: 1px solid rgba(255, 134, 195, 0.3);
            transition: all 0.2s ease;
            font-weight: 500;
        }

        article a:hover{
            color: var(--pink);
            border-bottom-color: var(--pink);
            text-shadow: 0 0 8px rgba(255, 46, 136, 0.4);
        }

        article a:visited{
            color: color-mix(in oklab, var(--pink-2) 80%, var(--muted) 20%);
        }

        /* Code blocks */
        pre{
            background: #0f0f1b;
            border: 1px solid #2a2a3a;
            color: #e2e8f0;
            padding: 1.25rem;
            border-radius: 12px;
            margin: 1.5rem 0;
            overflow-x: auto;
            font-family: var(--mono);
            font-size: 0.875rem;
            line-height: 1.6;
            box-shadow: inset 0 2px 8px rgba(0,0,0,.3);
        }

        code{
            font-family: var(--mono);
            font-size: 0.9em;
            background: rgba(255, 46, 136, 0.1);
            padding: 0.2rem 0.4rem;
            border-radius: 4px;
            color: var(--pink-2);
        }

        pre code{
            background: none;
            padding: 0;
            color: #e2e8f0;
        }

        /* JavaScript Syntax Highlighting */
        .language-javascript .keyword { color: #ff79c6; font-weight: 600; }
        .language-javascript .function { color: #8be9fd; }
        .language-javascript .string { color: #f1fa8c; }
        .language-javascript .number { color: #bd93f9; }
        .language-javascript .comment { color: #6272a4; font-style: italic; }
        .language-javascript .operator { color: #ff79c6; }
        .language-javascript .class-name { color: #50fa7b; }
        .language-javascript .constant { color: #ff79c6; }
        .language-javascript .punctuation { color: #a5a7bf; }
        .language-javascript .boolean { color: #bd93f9; font-weight: 600; }
        .language-javascript .null { color: #bd93f9; font-weight: 600; }
        .language-javascript .undefined { color: #bd93f9; font-weight: 600; }

        /* ASCII diagram container */
        pre.ascii-diagram {
            background: #0a0a14;
            border: 1px solid color-mix(in oklab, var(--pink) 25%, #2a2a3a 75%);
            color: var(--muted);
            font-size: 0.8rem;
            line-height: 1.4;
        }

        /* Canvas diagrams */
        .diagram-container {
            background: #0a0a14;
            border: 1px solid color-mix(in oklab, var(--pink) 25%, #2a2a3a 75%);
            border-radius: 12px;
            padding: 1rem;
            margin: 1.5rem 0;
            display: flex;
            justify-content: center;
            align-items: center;
            box-shadow: inset 0 2px 8px rgba(0,0,0,.3);
        }

        .diagram-canvas {
            display: block;
            width: 100%;
            height: auto;
        }

        /* Tables */
        table{
            width: 100%;
            border-collapse: collapse;
            margin: 1.5rem 0;
            background: var(--panel);
            border: 1px solid #2a2a3a;
            border-radius: 8px;
            overflow: hidden;
        }

        th{
            background: linear-gradient(180deg, color-mix(in oklab, var(--pink) 15%, var(--panel) 85%), var(--panel-2));
            color: var(--text);
            padding: 0.75rem;
            text-align: left;
            font-weight: 600;
            border-bottom: 1px solid color-mix(in oklab, var(--pink) 30%, #2a2a3a 70%);
        }

        td{
            padding: 0.75rem;
            border-bottom: 1px solid #2a2a3a;
            color: #d9d9ec;
        }

        tr:last-child td{
            border-bottom: none;
        }

        tr:hover{
            background: rgba(255, 46, 136, 0.05);
        }

        /* Blockquotes */
        blockquote{
            border-left: 3px solid var(--pink);
            background: #0a0a14;
            padding: 1rem 1.25rem;
            margin: 1.5rem 0;
            border-radius: 4px;
            font-style: italic;
            color: #d9d9ec;
        }

        blockquote p{
            margin-bottom: 0.5rem;
            margin-top: 0;
        }

        blockquote p:last-child{
            margin-bottom: 0;
        }

        /* Navigation */
        .article-nav{
            display: flex;
            justify-content: space-between;
            gap: 1rem;
            margin: 3rem 0;
            padding-top: 2rem;
            border-top: 1px solid var(--line);
        }

        .nav-link{
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            color: var(--pink-2);
            text-decoration: none;
            font-weight: 600;
            transition: transform 0.2s;
        }

        .nav-link:hover{
            color: var(--pink);
            transform: translateX(3px);
        }

        .nav-link.prev:hover{
            transform: translateX(-3px);
        }

        /* Footer */
        footer{
            border-top: 1px solid var(--line);
            background: #0a0a12;
            color: var(--muted);
            padding: 1rem 0 1.5rem;
            font-size: 0.875rem;
            margin-top: 4rem;
        }

        footer a{
            color: var(--pink-2);
            text-decoration: none;
            border-bottom: 1px solid rgba(255, 134, 195, 0.3);
            transition: all 0.2s ease;
        }

        footer a:hover{
            color: var(--pink);
            border-bottom-color: var(--pink);
            text-shadow: 0 0 8px rgba(255, 46, 136, 0.4);
        }

        /* Responsive */
        @media (max-width: 768px){
            article{
                padding: 1.5rem;
            }

            h1{
                font-size: 2rem;
            }

            .article-meta{
                font-size: 0.8rem;
                gap: 1rem;
            }

            pre{
                padding: 1rem;
                font-size: 0.75rem;
            }

            .diagram-container {
                padding: 1rem;
            }

            .diagram-canvas {
                width: 100%;
                height: auto;
            }
        }
    </style>
</head>
<body>
    <!-- Header/Navigation -->
    <header>
        <nav class="container">
            <a href="index.html" class="logo">
                The Gift of <span class="pink">Gab</span>
            </a>
            <a href="index.html" class="back-btn">
                Back to Home
            </a>
        </nav>
    </header>

    <!-- Main Article Content -->
    <main class="container">
        <article>
            <h1>Part 4: Attention</h1>

            <p>
                In this part, we'll transform our RNN-based model into a GPT-2 style transformer. We'll keep our tokenizer and embedding layer, but replace the recurrent core with attention mechanisms. Here's what we're building:
            </p>

            <div class="diagram-container">
                <canvas id="transformerPipelineDiagram" class="diagram-canvas" width="900" height="260" role="img" aria-label="Flow from token IDs through token and positional embeddings, transformer blocks, output layer, and softmax probabilities."></canvas>
            </div>

            <h2>What We Have vs. What We Need</h2>

            <table>
                <thead>
                    <tr>
                        <th>Component</th>
                        <th>ChatRNN (Part 3)</th>
                        <th>GPT-2 Style Transformer</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Tokenization</td>
                        <td>BPE &#10003;</td>
                        <td>BPE &#10003;</td>
                    </tr>
                    <tr>
                        <td>Embeddings</td>
                        <td>Token embeddings &#10003;</td>
                        <td>Token + <strong>Positional</strong> embeddings</td>
                    </tr>
                    <tr>
                        <td>Sequence processing</td>
                        <td>RNN (sequential)</td>
                        <td><strong>Self-Attention</strong> (parallel)</td>
                    </tr>
                    <tr>
                        <td>Architecture</td>
                        <td>RNN layers with residuals</td>
                        <td><strong>Transformer decoder blocks</strong></td>
                    </tr>
                    <tr>
                        <td>Normalization</td>
                        <td>None</td>
                        <td><strong>Layer Normalization</strong></td>
                    </tr>
                    <tr>
                        <td>Feed-forward</td>
                        <td>None (RNN hidden state only)</td>
                        <td><strong>MLP blocks</strong> after attention</td>
                    </tr>
                </tbody>
            </table>

            <p>
                We already have the tokenizer and embedding layer. Now we need to add positional embeddings, build the attention mechanism, implement layer normalization, and create MLP blocks. 
            </p>

            <h1>Positional Embeddings</h1>

            <p>
                RNNs know token order implicitly, they process tokens one at a time, so position is baked into the computation. But attention processes all tokens simultaneously. Without positional information, "the cat sat on the mat" and "mat the on sat cat the" would look identical to the network.
            </p>

            <p>
                Positional embeddings solve this by adding position-specific vectors to each token embedding. Token 0 gets one vector added, token 1 gets a different vector, and so on. The network learns these vectors during training, just like token embeddings.
            </p>

            <div class="diagram-container">
                <canvas id="positionalEmbeddingDiagram" class="diagram-canvas" width="750" height="340" role="img" aria-label="Token embeddings plus positional embeddings equals final embeddings for each token position."></canvas>
            </div>

            <p>
                We'll implement positional embeddings using composition, wrapping the existing <code>EmbeddingLayer</code> rather than modifying it:
            </p>

            <pre><code>class PositionalEmbeddingLayer {
    tokenEmbedding = null;
    positionWeights = null;
    maxSequenceLength = 0;
    embeddingDim = 0;
    cachedLength = 0;

    constructor(vocabSize, embeddingDim, maxSequenceLength) {
        this.embeddingDim = embeddingDim;
        this.maxSequenceLength = maxSequenceLength;

        // Reuse existing token embedding layer
        this.tokenEmbedding = new EmbeddingLayer(vocabSize, embeddingDim);

        // Initialize learnable position embeddings
        const scale = Math.sqrt(1.0 / embeddingDim);
        this.positionWeights = new Array(maxSequenceLength);
        for (let pos = 0; pos < maxSequenceLength; pos++) {
            this.positionWeights[pos] = new Array(embeddingDim);
            for (let d = 0; d < embeddingDim; d++) {
                this.positionWeights[pos][d] = (Math.random() * 2 - 1) * scale;
            }
        }
    }
}</code></pre>

            <p>
                The <code>maxSequenceLength</code> parameter sets the longest sequence we can handle. GPT-2 used 1024 positions; we'll use smaller values for our examples. The position weights are initialized the same way as token embeddings—small random values scaled by embedding dimension.
            </p>

            <h3>Positional Embedding Forward Pass</h3>

            <p>
                The forward pass looks up token embeddings, then adds the corresponding position embedding to each:
            </p>

            <pre><code>// ... class PositionalEmbeddingLayer
    forward(inputTokens) {
        // Get token embeddings from the wrapped layer
        const tokenEmbeddings = this.tokenEmbedding.forward(inputTokens);
        this.cachedLength = inputTokens.length;

        // Add position embeddings
        const output = new Array(inputTokens.length);
        for (let pos = 0; pos < inputTokens.length; pos++) {
            output[pos] = new Array(this.embeddingDim);
            for (let d = 0; d < this.embeddingDim; d++) {
                output[pos][d] = tokenEmbeddings[pos][d] + this.positionWeights[pos][d];
            }
        }

        return output;
    }</code></pre>

            <p>
                If the input is <code>[42, 17, 8]</code>, we look up embeddings for tokens 42, 17, and 8, then add position embeddings 0, 1, and 2 respectively. The result is a sequence of vectors where each vector encodes both "what token is this?" and "where in the sequence is it?"
            </p>

            <h3>Positional Embedding Backward Pass</h3>

            <p>
                During backpropagation, gradients flow to both the token embeddings and position embeddings. The addition operation during forward pass means the same gradient goes to both:
            </p>

            <pre><code>// ... class PositionalEmbeddingLayer
    backward(outputGradients, learningRate) {
        // Update position embeddings
        for (let pos = 0; pos < this.cachedLength; pos++) {
            for (let d = 0; d < this.embeddingDim; d++) {
                this.positionWeights[pos][d] -= learningRate * outputGradients[pos][d];
            }
        }

        // Pass gradients to token embeddings
        this.tokenEmbedding.backward(outputGradients, learningRate);

        return null; // First layer, no gradients to pass back
    }</code></pre>

            <blockquote>
                <p>Different models handle positions differently. GPT-1 used learned positional embeddings like we're implementing here. The original Transformer paper used fixed sinusoidal patterns. Modern models like RoPE (Rotary Position Embedding) encode positions through rotation matrices. Learned embeddings are simplest to implement and work well in practice.</p>
            </blockquote>

            <h1>Layer Normalization</h1>

            <p>
                Before diving into attention, we need layer normalization. Deep networks suffer from internal covariate shift: as earlier layers update during training, the distribution of inputs to later layers changes, making learning unstable. Layer normalization fixes this by normalizing activations at each layer.
            </p>

            <p>
                For each position in the sequence, we compute the mean and variance across the feature dimension, then normalize so the values have mean 0 and variance 1. We then apply learnable scale (gamma) and shift (beta) parameters that let the network undo the normalization if that's beneficial.
            </p>

            <div class="diagram-container">
                <canvas id="layerNormDiagram" class="diagram-canvas" width="700" height="320" role="img" aria-label="Layer normalization process: input values are normalized using mean and variance, then scaled and shifted."></canvas>
            </div>

            <p>
                The gamma and beta parameters are learnable, one value per feature dimension. They start at 1 and 0 respectively, meaning initially the layer just normalizes. During training, the network can learn to scale and shift specific features.
            </p>

            <pre><code>class LayerNormalization {
    gamma = null;       // Scale parameters (learnable)
    beta = null;        // Shift parameters (learnable)
    featureSize = 0;
    epsilon = 1e-5;     // Prevents division by zero

    // Cached values for backpropagation
    cachedInputs = null;
    cachedMean = null;
    cachedVariance = null;
    cachedNormalized = null;

    constructor(featureSize) {
        this.featureSize = featureSize;

        // Initialize gamma to 1 (no scaling initially)
        this.gamma = new Array(featureSize);
        for (let i = 0; i < featureSize; i++) {
            this.gamma[i] = 1.0;
        }

        // Initialize beta to 0 (no shifting initially)
        this.beta = new Array(featureSize);
        for (let i = 0; i < featureSize; i++) {
            this.beta[i] = 0.0;
        }
    }
}</code></pre>

            <h3>Layer Normalization Forward Pass</h3>

            <p>
                The forward pass normalizes each position in the sequence independently:
            </p>

            <pre><code>// ... class LayerNormalization
    forward(inputs) {
        const seqLength = inputs.length;

        // Initialize caches
        this.cachedInputs = new Array(seqLength);
        this.cachedMean = new Array(seqLength);
        this.cachedVariance = new Array(seqLength);
        this.cachedNormalized = new Array(seqLength);

        const outputs = new Array(seqLength);

        for (let t = 0; t < seqLength; t++) {
            // Cache input
            this.cachedInputs[t] = new Array(this.featureSize);
            for (let i = 0; i < this.featureSize; i++) {
                this.cachedInputs[t][i] = inputs[t][i];
            }

            // Compute mean
            let mean = 0;
            for (let i = 0; i < this.featureSize; i++) {
                mean += inputs[t][i];
            }
            mean /= this.featureSize;
            this.cachedMean[t] = mean;

            // Compute variance
            let variance = 0;
            for (let i = 0; i < this.featureSize; i++) {
                const diff = inputs[t][i] - mean;
                variance += diff * diff;
            }
            variance /= this.featureSize;
            this.cachedVariance[t] = variance;

            // Normalize and apply gamma/beta
            const stdDev = Math.sqrt(variance + this.epsilon);
            this.cachedNormalized[t] = new Array(this.featureSize);
            outputs[t] = new Array(this.featureSize);

            for (let i = 0; i < this.featureSize; i++) {
                const normalized = (inputs[t][i] - mean) / stdDev;
                this.cachedNormalized[t][i] = normalized;
                outputs[t][i] = this.gamma[i] * normalized + this.beta[i];
            }
        }

        return outputs;
    }</code></pre>

            <p>
                Each position gets normalized independently. We cache everything needed for backpropagation: the original inputs, mean, variance, and normalized values.
            </p>

            <h3>Layer Normalization Backward Pass</h3>

            <p>
                The backward pass is more complex because each output depends on all inputs at that position (through the mean and variance computation):
            </p>

            <pre><code>// ... class LayerNormalization
    backward(outputGradients, learningRate) {
        const seqLength = outputGradients.length;
        const inputGradients = new Array(seqLength);

        // Accumulate gradients for gamma and beta across all positions
        const gammaGrad = new Array(this.featureSize);
        const betaGrad = new Array(this.featureSize);
        for (let i = 0; i < this.featureSize; i++) {
            gammaGrad[i] = 0;
            betaGrad[i] = 0;
        }

        for (let t = 0; t < seqLength; t++) {
            const mean = this.cachedMean[t];
            const variance = this.cachedVariance[t];
            const stdDev = Math.sqrt(variance + this.epsilon);

            // Accumulate gamma and beta gradients
            for (let i = 0; i < this.featureSize; i++) {
                gammaGrad[i] += outputGradients[t][i] * this.cachedNormalized[t][i];
                betaGrad[i] += outputGradients[t][i];
            }

            // Compute gradient with respect to normalized values
            const dNormalized = new Array(this.featureSize);
            for (let i = 0; i < this.featureSize; i++) {
                dNormalized[i] = outputGradients[t][i] * this.gamma[i];
            }

            // Gradient through normalization
            // d/dx of (x - mean) / std involves terms for both the direct path
            // and the paths through mean and variance

            let dVariance = 0;
            for (let i = 0; i < this.featureSize; i++) {
                dVariance += dNormalized[i] * (this.cachedInputs[t][i] - mean);
            }
            dVariance *= -0.5 * Math.pow(variance + this.epsilon, -1.5);

            let dMean = 0;
            for (let i = 0; i < this.featureSize; i++) {
                dMean += dNormalized[i] * (-1.0 / stdDev);
            }
            dMean += dVariance * (-2.0 / this.featureSize) *
                     this.#sum(this.cachedInputs[t], mean);

            // Final input gradients
            inputGradients[t] = new Array(this.featureSize);
            for (let i = 0; i < this.featureSize; i++) {
                inputGradients[t][i] =
                    dNormalized[i] / stdDev +
                    dVariance * 2.0 * (this.cachedInputs[t][i] - mean) / this.featureSize +
                    dMean / this.featureSize;
            }
        }

        // Update gamma and beta
        for (let i = 0; i < this.featureSize; i++) {
            this.gamma[i] -= learningRate * gammaGrad[i];
            this.beta[i] -= learningRate * betaGrad[i];
        }

        return inputGradients;
    }

    #sum(arr, subtract) {
        let result = 0;
        for (let i = 0; i < arr.length; i++) {
            result += arr[i] - subtract;
        }
        return result;
    }</code></pre>

            <p>
                The gradient computation looks intimidating, but it follows the chain rule through three paths: the direct path from normalized output to input, the path through the mean, and the path through the variance. Each input value affects the mean, which affects all normalized values. Same for variance. These dependencies create cross-terms in the gradient.
            </p>

            <h1>Self-Attention</h1>

            <p>
                RNNs process tokens one at a time, carrying forward a hidden state. This creates two problems:
            </p>

            <ol>
                <li><strong>Information compression</strong>: By the time an RNN reaches token 50, information about token 1 has been compressed and re-compressed through 49 state updates. Details get lost.</li>
                <li><strong>No direct connections</strong>: Token 50 can't directly "look at" token 1. It only sees what the hidden state remembers.</li>
            </ol>

            <p>
                Consider the sentence: "The knight dropped his sword because it was heavy."
            </p>

            <p>
                What does "it" refer to? The knight or the sword? As humans, we instantly connect "it" to "sword" because swords are heavy. An RNN would have to hope this connection survived the hidden state compression. Self-attention solves this by letting every token directly look at every other token and decide what's relevant.
            </p>

            <p>
                Think of self-attention as every word performing a database lookup against all other words. For each word:
            </p>

            <ol>
                <li>Create a QUERY - "What am I looking for?"</li>
                <li>Every word has a KEY - "What do I contain?"</li>
                <li>Every word has a VALUE - "Here's my actual info"</li>
                <li>Compare my QUERY against all KEYs (similarity scores)</li>
                <li>Convert scores to percentages (softmax)</li>
                <li>Grab a weighted mix of all VALUEs</li>
            </ol>

            <h1>Query, Key, Value - What Are They?</h1>

            <p>
                These three vectors are computed from each token's embedding using learned weight matrices:
            </p>

            <pre><code>// Each token embedding gets transformed three ways:
query = embedding &#215; weightsQ   // "What am I looking for?"
key   = embedding &#215; weightsK   // "What do I contain?"
value = embedding &#215; weightsV   // "My actual information"</code></pre>

            <p><strong>Why three separate transformations?</strong></p>

            <p>
                Query and Key exist for <em>matching</em>. The network learns to make pronouns' queries match nouns' keys, verbs' queries match subjects' keys, etc.
            </p>

            <p>
                Value is for <em>content</em>. Once you've decided "sword" is relevant to "it", you don't want the matching score - you want the actual semantic content of "sword".
            </p>

            <ul>
                <li><strong>Key</strong> = The book's catalog entry (what you search by)</li>
                <li><strong>Value</strong> = The book's contents (what you actually read)</li>
                <li><strong>Query</strong> = Your search terms</li>
            </ul>

            <p>
                The Q/K/V pattern appears everywhere in databases. Self-attention is essentially a differentiable, learned lookup table where the matching function is trained end-to-end. Let's trace through a sentence: <code>["The", "cat", "sat"]</code>
            </p>

            <p>
                Each word starts as an embedding vector (say, 4 dimensions for simplicity):
            </p>

            <pre class="ascii-diagram">
"The" embedding: [0.2, -0.1, 0.5, 0.3]
"cat" embedding: [0.8, 0.4, -0.2, 0.1]
"sat" embedding: [-0.3, 0.6, 0.1, 0.7]</pre>

            <p><strong>Step 1: Compute Q, K, V for each token</strong></p>

            <pre class="ascii-diagram">
"The": query=[...], key=[...], value=[...]
"cat": query=[...], key=[...], value=[...]
"sat": query=[...], key=[...], value=[...]</pre>

            <p><strong>Step 2: Each token scores against all keys</strong></p>

            <p>Let's focus on "sat" computing its scores:</p>

            <pre class="ascii-diagram">
score("sat" &#8594; "The") = dot(query_sat, key_The) = 0.3
score("sat" &#8594; "cat") = dot(query_sat, key_cat) = 1.8  // High! Verbs look for subjects
score("sat" &#8594; "sat") = dot(query_sat, key_sat) = 0.5

scores = [0.3, 1.8, 0.5]</pre>

            <p><strong>Step 3: Convert to percentages (softmax)</strong></p>

            <pre class="ascii-diagram">
weights = softmax([0.3, 1.8, 0.5]) = [0.15, 0.62, 0.23]
                                      &#9474;     &#9474;     &#9474;
                                     The   cat   sat</pre>

            <p>"sat" puts 62% of its attention on "cat", 23% on itself, 15% on "The".</p>

            <p><strong>Step 4: Weighted sum of values</strong></p>

            <pre class="ascii-diagram">
output_sat = 0.15 &#215; value_The + 0.62 &#215; value_cat + 0.23 &#215; value_sat</pre>

            <p>
                The output for "sat" is now enriched with information from "cat" - the subject it was looking for.
            </p>

            <h1>The Causal Mask</h1>

            <p>
                For language models, there's a constraint: when predicting the next word, you can't look at future words (they don't exist yet during generation). Token at position <code>i</code> can only see positions <code>0</code> through <code>i</code>:
            </p>

            <div class="diagram-container">
                <canvas id="causalMaskDiagram" class="diagram-canvas" width="800" height="280" role="img" aria-label="Causal mask showing which positions each token can attend to."></canvas>
            </div>

            <p>
                We implement this by setting "future" scores to negative infinity before softmax. After softmax, negative infinity becomes 0%, so future tokens contribute nothing.
            </p>

            <pre><code>// Before masking: scores = [0.3, 1.8, 0.5, 0.9]
// After masking:  scores = [0.3, 1.8, -Infinity, -Infinity]
// After softmax:  weights = [0.18, 0.82, 0.0, 0.0]</code></pre>

            <h1>The Scaling Factor</h1>

            <p>
                Before softmax, we divide scores by <code>sqrt(dimension)</code>. Why? Dot products grow larger as dimensions increase. Large values going into softmax produce extremely peaked distributions (nearly one-hot), which causes gradient problems during training. Scaling keeps the values in a reasonable range.
            </p>

            <pre><code>const scale = Math.sqrt(headDim);
for (let j = 0; j < scores.length; j++) {
    scores[j] /= scale;
}</code></pre>

            <blockquote>
                <p>This is why it's called "Scaled Dot-Product Attention" in the literature. The scaling is a practical necessity, not a theoretical insight.</p>
            </blockquote>

            <h1>Multi-Head Attention</h1>

            <p>
                Each attention head has its own Q, K, V weight matrices that project from the <strong>full embedding dimension</strong> down to a smaller <strong>head dimension</strong>. If your embedding is 64-dimensional and you have 4 heads, each head projects the full 64-dimensional input down to 16 dimensions.
            </p>

            <pre class="ascii-diagram">
Input embedding: [64 dimensions]
         &#9474;
         &#9500;&#9472;&#9472;&#9658; Head 0: weightsQ[64][16] &#9472;&#9472;&#9658; query[16]
         &#9500;&#9472;&#9472;&#9658; Head 1: weightsQ[64][16] &#9472;&#9472;&#9658; query[16]
         &#9500;&#9472;&#9472;&#9658; Head 2: weightsQ[64][16] &#9472;&#9472;&#9658; query[16]
         &#9492;&#9472;&#9472;&#9658; Head 3: weightsQ[64][16] &#9472;&#9472;&#9658; query[16]</pre>

            <p>
                Each head sees the <strong>entire</strong> input vector, but projects it into its own 16-dimensional subspace. Think of it like four different cameras photographing the same scene from different angles—each captures the whole scene, but emphasizes different aspects.
            </p>

            <p>
                The weight matrices learn these projections during training. Head 0 might learn to project inputs in a way that captures syntactic relationships. Head 1 might learn projections that capture semantic similarity. Each head develops its own "perspective" on the data.
            </p>

            <p>
                After attention, each head produces a 16-dimensional output for each position. We concatenate these outputs:
            </p>

            <pre class="ascii-diagram">
Head 0 output: [16] &#9472;&#9488;
Head 1 output: [16] &#9472;&#9532;&#9472;&#9472;&#9658; Concatenated: [64]
Head 2 output: [16] &#9472;&#9508;
Head 3 output: [16] &#9472;&#9496;</pre>

            <p>
                The concatenated output is back to 64 dimensions (16 &#215; 4 = 64). We then apply an output projection—a learned linear transformation that mixes information across the head dimensions:
            </p>

            <pre class="ascii-diagram">
Concatenated [64] &#9472;&#9472;&#9658; Output Projection [64][64] &#9472;&#9472;&#9658; Final Output [64]</pre>

            <p>
                This output projection is crucial. Without it, the heads would operate completely independently. The projection lets the model combine insights from different heads—"Head 1 found the subject, Head 3 found the verb, now let's combine them."
            </p>

             <blockquote>
                <p>
                    Projecting a vector or matrix from one space or another is done with matrix multiplication. When you multiply a vector by a matrix, the output dimension is determined by the matrix shape: <code>vector [N] × matrix [N][M] = result [M]</code>
                    <ul>
                        <li>If M &lt; N: you're projecting down (compressing)</li>
                        <li>If M &gt; N: you're projecting up (expanding)</li>
                        <li>If M = N: same dimension (transforming)</li>
                    </ul>
                </p>
            </blockquote>

            <p>We'll build two classes:</p>
            <ol>
                <li><strong>AttentionHead</strong> - A single attention head with its own Q/K/V weights. This is the core computation unit.</li>
                <li><strong>MultiHeadAttentionLayer</strong> - Contains N AttentionHead instances, handles concatenation and output projection.</li>
            </ol>

            <h1>Helper Functions</h1>

            <p>Before building the classes, we need some utilities that both will use.</p>

            <pre><code>#createMatrix(rows, cols, fillValue = 0) {
    const matrix = new Array(rows);
    for (let i = 0; i < rows; i++) {
        matrix[i] = new Array(cols);
        for (let j = 0; j < cols; j++) {
            matrix[i][j] = fillValue;
        }
    }
    return matrix;
}</code></pre>

            <p>Creates a 2D array initialized to a fill value. We use regular nested arrays rather than typed arrays because we need flexibility with dimensions.</p>

            <pre><code>#randomMatrix(rows, cols, scale) {
    const matrix = new Array(rows);
    for (let i = 0; i < rows; i++) {
        matrix[i] = new Array(cols);
        for (let j = 0; j < cols; j++) {
            matrix[i][j] = (Math.random() * 2 - 1) * scale;
        }
    }
    return matrix;
}</code></pre>

            <p>Weight matrices need random initialization. The <code>scale</code> parameter controls the initial magnitude - we use Xavier initialization to keep activations stable.</p>

            <pre><code>#vectorMatrixMultiply(vector, matrix) {
    // vector: [inputDim], matrix: [inputDim][outputDim]
    // result: [outputDim]
    const outputDim = matrix[0].length;
    const result = new Array(outputDim);

    for (let j = 0; j < outputDim; j++) {
        let sum = 0;
        for (let i = 0; i < vector.length; i++) {
            sum += vector[i] * matrix[i][j];
        }
        result[j] = sum;
    }

    return result;
}</code></pre>

            <p>The Q, K, V projections require multiplying each embedding vector by a weight matrix. This computes <code>result[j] = &#931; vector[i] * matrix[i][j]</code> for each output dimension.</p>

            <pre><code>#dot(a, b) {
    let sum = 0;
    for (let i = 0; i < a.length; i++) {
        sum += a[i] * b[i];
    }
    return sum;
}</code></pre>

            <p>Comparing queries to keys requires dot products. The dot product measures similarity - high values mean the vectors point in similar directions.</p>

            <pre><code>#softmax(values) {
    // Find max for numerical stability
    let max = values[0];
    for (let i = 1; i < values.length; i++) {
        if (values[i] > max) max = values[i];
    }

    // Compute exp(value - max) and sum
    const exp = new Array(values.length);
    let sum = 0;
    for (let i = 0; i < values.length; i++) {
        exp[i] = Math.exp(values[i] - max);
        sum += exp[i];
    }

    // Normalize
    const result = new Array(values.length);
    for (let i = 0; i < values.length; i++) {
        result[i] = exp[i] / sum;
    }

    return result;
}</code></pre>

            <p>Converts scores to probabilities:</p>
            <ol>
                <li><strong>Subtract max first</strong> - Prevents numerical overflow. <code>exp(1000)</code> is infinity, but <code>exp(0) = 1</code>.</li>
                <li><strong>Exponentiate</strong> - Converts scores to positive values, amplifies differences.</li>
                <li><strong>Normalize</strong> - Divides by sum so outputs sum to 1.0.</li>
            </ol>

            <h1>The AttentionHead Class</h1>

            <p>An attention head is the core computation unit. It has its own Q, K, V weight matrices and performs the full attention computation on a reduced dimension.</p>

            <pre><code>class AttentionHead {
    weightsQ = null;  // [embeddingDim][headDim]
    weightsK = null;  // [embeddingDim][headDim]
    weightsV = null;  // [embeddingDim][headDim]

    embeddingDim = 0;
    headDim = 0;
    scale = 0;

    // Caches for backpropagation
    cachedInputs = null;
    cachedQ = null;
    cachedK = null;
    cachedV = null;
    cachedScores = null;
    cachedWeights = null;

    constructor(embeddingDim, headDim) {
        this.embeddingDim = embeddingDim;
        this.headDim = headDim;
        this.scale = Math.sqrt(headDim);

        const initScale = Math.sqrt(2.0 / (embeddingDim + headDim));

        this.weightsQ = this.#randomMatrix(embeddingDim, headDim, initScale);
        this.weightsK = this.#randomMatrix(embeddingDim, headDim, initScale);
        this.weightsV = this.#randomMatrix(embeddingDim, headDim, initScale);
    }
}</code></pre>

            <p><strong>What's stored:</strong></p>
            <ul>
                <li>Three weight matrices projecting from <code>embeddingDim</code> down to <code>headDim</code></li>
                <li>The scale factor (precomputed <code>sqrt(headDim)</code>)</li>
                <li>Caches for backpropagation</li>
            </ul>

            <p>Note that <code>weightsQ</code>, <code>weightsK</code>, and <code>weightsV</code> are <code>[embeddingDim][headDim]</code> - they project the full embedding down to the head's smaller dimension.</p>

            <h2>AttentionHead Forward Pass</h2>

            <pre><code>forward(inputs) {
    // inputs: [seqLen][embeddingDim]
    const seqLen = inputs.length;
    this.cachedInputs = inputs;

    // Step 1: Project inputs to Q, K, V in head dimension
    this.cachedQ = new Array(seqLen);
    this.cachedK = new Array(seqLen);
    this.cachedV = new Array(seqLen);

    for (let i = 0; i < seqLen; i++) {
        this.cachedQ[i] = this.#vectorMatrixMultiply(inputs[i], this.weightsQ);
        this.cachedK[i] = this.#vectorMatrixMultiply(inputs[i], this.weightsK);
        this.cachedV[i] = this.#vectorMatrixMultiply(inputs[i], this.weightsV);
    }

    // Step 2: Compute attention scores
    this.cachedScores = this.#createMatrix(seqLen, seqLen);

    for (let i = 0; i < seqLen; i++) {
        for (let j = 0; j < seqLen; j++) {
            if (j > i) {
                // Causal mask: can't attend to future positions
                this.cachedScores[i][j] = -Infinity;
            } else {
                this.cachedScores[i][j] = this.#dot(this.cachedQ[i], this.cachedK[j]) / this.scale;
            }
        }
    }

    // Step 3: Softmax to get attention weights
    this.cachedWeights = new Array(seqLen);
    for (let i = 0; i < seqLen; i++) {
        this.cachedWeights[i] = this.#softmax(this.cachedScores[i]);
    }

    // Step 4: Weighted sum of values
    const outputs = new Array(seqLen);
    for (let i = 0; i < seqLen; i++) {
        outputs[i] = new Array(this.headDim);
        for (let d = 0; d < this.headDim; d++) {
            let sum = 0;
            for (let j = 0; j <= i; j++) {
                sum += this.cachedWeights[i][j] * this.cachedV[j][d];
            }
            outputs[i][d] = sum;
        }
    }

    return outputs;  // [seqLen][headDim]
}</code></pre>

            <p>The forward pass implements exactly what we described earlier:</p>
            <ol>
                <li>Project each input to Q, K, V vectors (now in <code>headDim</code> space)</li>
                <li>Compute scores between all query-key pairs, with causal masking</li>
                <li>Softmax each row to get attention weights</li>
                <li>Weighted sum of values</li>
            </ol>

            <p>The output is <code>[seqLen][headDim]</code> - each position now contains information gathered from other positions.</p>

            <h2>AttentionHead Backward Pass</h2>

            <p>The backward pass traces the forward pass in reverse, computing gradients for the weights and passing gradients to the input:</p>

            <pre><code>backward(outputGradients, learningRate) {
    // outputGradients: [seqLen][headDim]
    const seqLen = this.cachedInputs.length;

    // Accumulators for weight gradients
    const weightsQGrad = this.#createMatrix(this.embeddingDim, this.headDim);
    const weightsKGrad = this.#createMatrix(this.embeddingDim, this.headDim);
    const weightsVGrad = this.#createMatrix(this.embeddingDim, this.headDim);

    // Gradients to pass to previous layer
    const inputGradients = new Array(seqLen);
    for (let i = 0; i < seqLen; i++) {
        inputGradients[i] = new Array(this.embeddingDim);
        for (let d = 0; d < this.embeddingDim; d++) {
            inputGradients[i][d] = 0;
        }
    }

    // ====== Step 4 backward: Weighted sum of values ======
    // output[i] = &#931; weights[i][j] * V[j]
    // Need gradients for weights and V

    const weightsGrad = this.#createMatrix(seqLen, seqLen);
    const vGrad = new Array(seqLen);
    for (let i = 0; i < seqLen; i++) {
        vGrad[i] = new Array(this.headDim);
        for (let d = 0; d < this.headDim; d++) {
            vGrad[i][d] = 0;
        }
    }

    for (let i = 0; i < seqLen; i++) {
        for (let j = 0; j <= i; j++) {
            for (let d = 0; d < this.headDim; d++) {
                weightsGrad[i][j] += outputGradients[i][d] * this.cachedV[j][d];
                vGrad[j][d] += outputGradients[i][d] * this.cachedWeights[i][j];
            }
        }
    }

    // ====== Step 3 backward: Softmax ======
    // weights = softmax(scores)
    const scoresGrad = this.#createMatrix(seqLen, seqLen);

    for (let i = 0; i < seqLen; i++) {
        for (let j = 0; j <= i; j++) {
            for (let k = 0; k <= i; k++) {
                if (j === k) {
                    scoresGrad[i][j] += weightsGrad[i][k] * this.cachedWeights[i][j] * (1 - this.cachedWeights[i][j]);
                } else {
                    scoresGrad[i][j] += weightsGrad[i][k] * (-this.cachedWeights[i][j] * this.cachedWeights[i][k]);
                }
            }
        }
    }

    // ====== Step 2 backward: Score computation ======
    // scores[i][j] = dot(Q[i], K[j]) / scale
    const qGrad = new Array(seqLen);
    const kGrad = new Array(seqLen);
    for (let i = 0; i < seqLen; i++) {
        qGrad[i] = new Array(this.headDim);
        kGrad[i] = new Array(this.headDim);
        for (let d = 0; d < this.headDim; d++) {
            qGrad[i][d] = 0;
            kGrad[i][d] = 0;
        }
    }

    for (let i = 0; i < seqLen; i++) {
        for (let j = 0; j <= i; j++) {
            const scaledGrad = scoresGrad[i][j] / this.scale;

            for (let d = 0; d < this.headDim; d++) {
                qGrad[i][d] += scaledGrad * this.cachedK[j][d];
                kGrad[j][d] += scaledGrad * this.cachedQ[i][d];
            }
        }
    }

    // ====== Step 1 backward: Q, K, V projections ======
    // Q = input &#215; weightsQ, etc.
    // Gradients flow through all three paths to input

    for (let i = 0; i < seqLen; i++) {
        // Q path
        for (let d = 0; d < this.embeddingDim; d++) {
            for (let h = 0; h < this.headDim; h++) {
                inputGradients[i][d] += qGrad[i][h] * this.weightsQ[d][h];
                weightsQGrad[d][h] += qGrad[i][h] * this.cachedInputs[i][d];
            }
        }

        // K path
        for (let d = 0; d < this.embeddingDim; d++) {
            for (let h = 0; h < this.headDim; h++) {
                inputGradients[i][d] += kGrad[i][h] * this.weightsK[d][h];
                weightsKGrad[d][h] += kGrad[i][h] * this.cachedInputs[i][d];
            }
        }

        // V path
        for (let d = 0; d < this.embeddingDim; d++) {
            for (let h = 0; h < this.headDim; h++) {
                inputGradients[i][d] += vGrad[i][h] * this.weightsV[d][h];
                weightsVGrad[d][h] += vGrad[i][h] * this.cachedInputs[i][d];
            }
        }
    }

    // Update weights
    for (let d = 0; d < this.embeddingDim; d++) {
        for (let h = 0; h < this.headDim; h++) {
            this.weightsQ[d][h] -= learningRate * weightsQGrad[d][h];
            this.weightsK[d][h] -= learningRate * weightsKGrad[d][h];
            this.weightsV[d][h] -= learningRate * weightsVGrad[d][h];
        }
    }

    return inputGradients;  // [seqLen][embeddingDim]
}</code></pre>

            <p>The input receives gradients from three paths. This is why we accumulate with <code>+=</code>. Each path contributes its portion of the error signal. Key points about the backward pass:</p>

            <ol>
                <li><strong>Step 4 backward</strong>: The weighted sum has two contributors - the attention weights and the values. Both receive gradients.</li>
                <li><strong>Step 3 backward</strong>: Softmax gradient is tricky because each output depends on all inputs (through normalization). The diagonal terms use <code>w * (1 - w)</code>, off-diagonal use <code>-w[j] * w[k]</code>.</li>
                <li><strong>Step 2 backward</strong>: The dot product gradient flows to both Q and K.</li>
                <li><strong>Step 1 backward</strong>: Three paths (Q, K, V) all came from the same input, so we sum all three contributions to <code>inputGradients</code>.</li>
            </ol>

            <h1>The MultiHeadAttentionLayer Class</h1>

            <p>This class orchestrates multiple attention heads, concatenates their outputs, and applies an output projection.</p>

            <pre><code>class MultiHeadAttentionLayer {
    heads = null;
    outputProj = null;  // DenseLayer: embeddingDim &#8594; embeddingDim

    numHeads = 0;
    headDim = 0;
    embeddingDim = 0;

    // Caches
    cachedHeadOutputs = null;
    cachedConcatenated = null;

    constructor(embeddingDim, numHeads) {
        if (embeddingDim % numHeads !== 0) {
            throw new Error("embeddingDim must be divisible by numHeads");
        }

        this.embeddingDim = embeddingDim;
        this.numHeads = numHeads;
        this.headDim = embeddingDim / numHeads;

        // Create attention heads
        this.heads = new Array(numHeads);
        for (let h = 0; h < numHeads; h++) {
            this.heads[h] = new AttentionHead(embeddingDim, this.headDim);
        }

        // Output projection
        this.outputProj = new DenseLayer(embeddingDim, embeddingDim);
    }
}</code></pre>

            <p>Each head projects the full embedding dimension down to <code>headDim</code>. With 4 heads and 64 embedding dim, each head works with 16 dimensions. After concatenation, we're back to 64. The output projection then mixes information across head dimensions using our familiar <code>DenseLayer</code>.</p>

            <h2>MultiHeadAttentionLayer Forward Pass</h2>

            <pre><code>forward(inputs) {
    // inputs: [seqLen][embeddingDim]
    const seqLen = inputs.length;

    // Run each head
    this.cachedHeadOutputs = new Array(this.numHeads);
    for (let h = 0; h < this.numHeads; h++) {
        this.cachedHeadOutputs[h] = this.heads[h].forward(inputs);
        // Each head output: [seqLen][headDim]
    }

    // Concatenate head outputs
    this.cachedConcatenated = new Array(seqLen);
    for (let i = 0; i < seqLen; i++) {
        this.cachedConcatenated[i] = new Array(this.embeddingDim);

        for (let h = 0; h < this.numHeads; h++) {
            for (let d = 0; d < this.headDim; d++) {
                this.cachedConcatenated[i][h * this.headDim + d] = this.cachedHeadOutputs[h][i][d];
            }
        }
    }

    // Output projection using DenseLayer
    const outputs = new Array(seqLen);
    for (let i = 0; i < seqLen; i++) {
        outputs[i] = this.outputProj.forward(this.cachedConcatenated[i]);
    }

    return outputs;  // [seqLen][embeddingDim]
}</code></pre>

            <p>The forward pass:</p>
            <ol>
                <li><strong>Run all heads</strong>: Each head receives the same input and produces <code>[seqLen][headDim]</code> output</li>
                <li><strong>Concatenate</strong>: Stack head outputs side-by-side to get <code>[seqLen][embeddingDim]</code></li>
                <li><strong>Output projection</strong>: Our <code>DenseLayer</code> transforms each position</li>
            </ol>

            <p>The concatenation places head 0's output in positions <code>[0..headDim-1]</code>, head 1's in <code>[headDim..2*headDim-1]</code>, etc.</p>

            <h2>MultiHeadAttentionLayer Backward Pass</h2>

            <pre><code>backward(outputGradients, learningRate) {
    // outputGradients: [seqLen][embeddingDim]
    const seqLen = outputGradients.length;

    // ====== Output projection backward using DenseLayer ======
    const concatenatedGrad = new Array(seqLen);

    for (let i = 0; i < seqLen; i++) {
        // Re-forward to set up DenseLayer cache for this position
        this.outputProj.forward(this.cachedConcatenated[i]);
        // Backward through the dense layer
        concatenatedGrad[i] = this.outputProj.backward(outputGradients[i], learningRate);
    }

    // ====== Concatenation backward: split gradients to each head ======
    const headGradients = new Array(this.numHeads);
    for (let h = 0; h < this.numHeads; h++) {
        headGradients[h] = new Array(seqLen);
        for (let i = 0; i < seqLen; i++) {
            headGradients[h][i] = new Array(this.headDim);
            for (let d = 0; d < this.headDim; d++) {
                headGradients[h][i][d] = concatenatedGrad[i][h * this.headDim + d];
            }
        }
    }

    // ====== Run backward on each head and sum input gradients ======
    const inputGradients = new Array(seqLen);
    for (let i = 0; i < seqLen; i++) {
        inputGradients[i] = new Array(this.embeddingDim);
        for (let d = 0; d < this.embeddingDim; d++) {
            inputGradients[i][d] = 0;
        }
    }

    for (let h = 0; h < this.numHeads; h++) {
        const headInputGrad = this.heads[h].backward(headGradients[h], learningRate);

        // Sum input gradients from all heads
        for (let i = 0; i < seqLen; i++) {
            for (let d = 0; d < this.embeddingDim; d++) {
                inputGradients[i][d] += headInputGrad[i][d];
            }
        }
    }

    return inputGradients;  // [seqLen][embeddingDim]
}</code></pre>

            <p>The backward pass:</p>
            <ol>
                <li><strong>Output projection backward</strong>: <code>DenseLayer</code> handles its own gradient computation and weight updates</li>
                <li><strong>Concatenation backward</strong>: This is just slicing—each head's gradient is its slice of <code>concatenatedGrad</code></li>
                <li><strong>Head backward</strong>: Run backward on each head, which updates its Q/K/V weights and returns input gradients</li>
                <li><strong>Sum input gradients</strong>: All heads received the same input, so their gradients sum</li>
            </ol>

            <blockquote>
                <p>Each head independently updates its own Q/K/V weights during its backward pass. The <code>MultiHeadAttentionLayer</code> just needs to route gradients appropriately—<code>DenseLayer</code> handles the output projection weights automatically.</p>
            </blockquote>

            <h1>Attention Recap</h1>

            <p>Self-attention is a <strong>learned, differentiable lookup mechanism</strong>:</p>

            <ol>
                <li>Each token creates a <strong>Query</strong> ("what am I looking for?")</li>
                <li>Each token creates a <strong>Key</strong> ("what do I contain?")</li>
                <li>Each token creates a <strong>Value</strong> ("here's my information")</li>
                <li>Scores are <strong>masked</strong> (for causal models) and <strong>softmaxed</strong> to get weights</li>
                <li>Each token takes a <strong>weighted sum</strong> of all values it can see</li>
                <li>An <strong>output projection</strong> combines information across heads</li>
            </ol>

            <p><strong>Insights and architecture:</strong></p>
            <ul>
                <li><code>AttentionHead</code> handles one set of Q/K/V projections and computes attention in a reduced dimension</li>
                <li><code>MultiHeadAttentionLayer</code> contains N <code>AttentionHead</code> instances, concatenates their outputs, and applies an output projection</li>
                <li>Single-head attention is just <code>MultiHeadAttentionLayer</code> with <code>numHeads = 1</code></li>
                <li>Attention is O(n&#178;) in sequence length - every token looks at every other token</li>
                <li>Multi-head attention lets the network learn multiple types of relationships</li>
                <li>More heads = more types of relationships the model can learn</li>
                <li>All heads receive the same input, so their input gradients sum during backprop</li>
            </ul>

            <p>This mechanism, combined with layer normalization and feed-forward networks, forms the transformer block - the building block of GPT and most modern language models.</p>

            <h1>The MLP Block</h1>

            <p>
                After attention gathers information from across the sequence, the MLP (Multi-Layer Perceptron) block processes each position independently. The MLP block is simple: two linear transformations with a non-linearity in between. The first layer expands the representation (typically 4x the embedding dimension), applies an activation function, then the second layer projects back down.
            </p>

            <div class="diagram-container">
                <canvas id="mlpBlockDiagram" class="diagram-canvas" width="750" height="180" role="img" aria-label="MLP block showing input through Dense1, GELU activation, Dense2 to output."></canvas>
            </div>

            <h2>Adding GELU to ActivationLayer</h2>

            <p>
                First, we need to extend the <code>ActivationLayer</code> class to support GELU (Gaussian Error Linear Unit). GELU smoothly gates inputs based on their value: large positive values pass through mostly unchanged, large negative values are suppressed, and values near zero get partially dampened.
            </p>

            <pre><code>// Add to ActivationLayer from Part 1:
    #geluActivation(x) {
        // Approximation: 0.5 * x * (1 + tanh(sqrt(2/&#960;) * (x + 0.044715 * x&#179;)))
        const c = Math.sqrt(2 / Math.PI);
        return 0.5 * x * (1 + Math.tanh(c * (x + 0.044715 * x * x * x)));
    }

    #geluDerivative(x) {
        const c = Math.sqrt(2 / Math.PI);
        const x3 = x * x * x;
        const inner = c * (x + 0.044715 * x3);
        const tanhInner = Math.tanh(inner);
        const sech2 = 1 - tanhInner * tanhInner;
        const innerDeriv = c * (1 + 3 * 0.044715 * x * x);
        return 0.5 * (1 + tanhInner) + 0.5 * x * sech2 * innerDeriv;
    }</code></pre>

            <blockquote>
                <p>Why GELU over ReLU? ReLU has a hard cutoff at zero—anything negative becomes exactly zero, killing gradients. GELU's smooth curve means gradients always flow, even for slightly negative inputs. This helps with training stability.</p>
            </blockquote>

            <h2>MLP Block Implementation</h2>

            <p>
                We can implement MLPBlock by composing existing layers. Each position in the sequence is processed independently through the same dense layers. We cache all intermediate values during the forward pass so we don't need to recompute them during backward:
            </p>

            <pre><code>class MLPBlock {
    dense1 = null;      // embeddingDim &#8594; hiddenDim
    activation = null;  // GELU
    dense2 = null;      // hiddenDim &#8594; embeddingDim

    // Caches for backpropagation
    cachedInputs = null;
    cachedHidden1 = null;   // After dense1
    cachedHidden2 = null;   // After activation

    constructor(embeddingDim, expansionFactor = 4) {
        const hiddenDim = embeddingDim * expansionFactor;

        // Reuse our DenseLayer and ActivationLayer from Part 1!
        this.dense1 = new DenseLayer(embeddingDim, hiddenDim);
        this.activation = new ActivationLayer("gelu");
        this.dense2 = new DenseLayer(hiddenDim, embeddingDim);
    }
}</code></pre>

            <h3>MLP Forward Pass</h3>

            <p>The forward pass processes each position through our layer stack, caching all intermediate results:</p>

            <pre><code>// ... class MLPBlock
    forward(inputs) {
        // inputs: [seqLen][embeddingDim]
        const seqLen = inputs.length;

        // Cache everything we'll need for backward
        this.cachedInputs = inputs;
        this.cachedHidden1 = new Array(seqLen);
        this.cachedHidden2 = new Array(seqLen);

        const outputs = new Array(seqLen);

        for (let t = 0; t < seqLen; t++) {
            // Each position goes through: Dense1 &#8594; GELU &#8594; Dense2
            this.cachedHidden1[t] = this.dense1.forward(inputs[t]);
            this.cachedHidden2[t] = this.activation.forward(this.cachedHidden1[t]);
            outputs[t] = this.dense2.forward(this.cachedHidden2[t]);
        }

        return outputs;  // [seqLen][embeddingDim]
    }</code></pre>

            <p>The MLP treats each position identically, unlike attention which mixes information across positions. By caching <code>cachedHidden1</code> and <code>cachedHidden2</code> for every position, we have all the intermediate values needed for backpropagation.</p>

            <h3>MLP Backward Pass</h3>

            <p>The backward pass propagates gradients back through each position using the cached values:</p>

            <pre><code>// ... class MLPBlock
    backward(outputGradients, learningRate) {
        // outputGradients: [seqLen][embeddingDim]
        const seqLen = outputGradients.length;
        const inputGradients = new Array(seqLen);

        for (let t = 0; t < seqLen; t++) {
            // Restore layer caches for this position
            this.dense1.cachedInput = this.cachedInputs[t];
            this.activation.cachedInput = this.cachedHidden1[t];
            this.dense2.cachedInput = this.cachedHidden2[t];

            // Backward through the layers
            let grad = this.dense2.backward(outputGradients[t], learningRate);
            grad = this.activation.backward(grad);
            inputGradients[t] = this.dense1.backward(grad, learningRate);
        }

        return inputGradients;  // [seqLen][embeddingDim]
    }</code></pre>

            <blockquote>
                <p>The weights update after processing each position. This is slightly different from accumulating all gradients first, but converges to the same solution.</p>
            </blockquote>

            <h1>The Transformer Block</h1>

            <p>Now we can assemble the complete transformer block. Each block contains layer normalization, multi-head attention, another layer normalization, and an MLP, all connected with residual connections.</p>

            <div class="diagram-container">
                <canvas id="transformerBlockDiagram" class="diagram-canvas" width="850" height="180" role="img" aria-label="Transformer block showing Input through LayerNorm, Attention, LayerNorm, MLP to Output with residual connections."></canvas>
            </div>

            <p>
                The residual connections are crucial. They let gradients flow directly backward without passing through the attention or MLP transformations, solving the vanishing gradient problem. They also let the network learn "refinements" rather than complete transformations—the attention and MLP blocks learn what to <em>add</em> to the representation.
            </p>

            <pre><code>class TransformerBlock {
    layerNorm1 = null;
    attention = null;
    layerNorm2 = null;
    mlp = null;

    embeddingDim = 0;

    // Caches for residual connections
    cachedInput = null;
    cachedPostAttention = null;

    constructor(embeddingDim, numHeads, mlpExpansion = 4) {
        this.embeddingDim = embeddingDim;

        this.layerNorm1 = new LayerNormalization(embeddingDim);
        this.attention = new MultiHeadAttentionLayer(embeddingDim, numHeads);
        this.layerNorm2 = new LayerNormalization(embeddingDim);
        this.mlp = new MLPBlock(embeddingDim, mlpExpansion);
    }
}</code></pre>

            <p>The constructor creates all four sub-components. The <code>numHeads</code> parameter controls how many attention heads to use, and <code>mlpExpansion</code> (defaulting to 4) controls the MLP's hidden dimension.</p>

            <h3>Transformer Block Forward Pass</h3>

            <pre><code>// ... class TransformerBlock
    forward(inputs) {
        // inputs: [seqLen][embeddingDim]
        const seqLen = inputs.length;

        // Cache input for residual
        this.cachedInput = inputs;

        // Pre-norm attention block
        const normalized1 = this.layerNorm1.forward(inputs);
        const attended = this.attention.forward(normalized1);

        // First residual connection: input + attention output
        this.cachedPostAttention = new Array(seqLen);
        for (let t = 0; t < seqLen; t++) {
            this.cachedPostAttention[t] = new Array(this.embeddingDim);
            for (let d = 0; d < this.embeddingDim; d++) {
                this.cachedPostAttention[t][d] = inputs[t][d] + attended[t][d];
            }
        }

        // Pre-norm MLP block
        const normalized2 = this.layerNorm2.forward(this.cachedPostAttention);
        const mlpOutput = this.mlp.forward(normalized2);

        // Second residual connection: post-attention + MLP output
        const outputs = new Array(seqLen);
        for (let t = 0; t < seqLen; t++) {
            outputs[t] = new Array(this.embeddingDim);
            for (let d = 0; d < this.embeddingDim; d++) {
                outputs[t][d] = this.cachedPostAttention[t][d] + mlpOutput[t][d];
            }
        }

        return outputs;  // [seqLen][embeddingDim]
    }</code></pre>

            <p>The forward pass follows this path:</p>
            <ol>
                <li>LayerNorm &#8594; Attention &#8594; Add residual from input</li>
                <li>LayerNorm &#8594; MLP &#8594; Add residual from step 1</li>
            </ol>

            <p>We cache intermediate values at the residual connection points because backward needs them.</p>

            <h3>Transformer Block Backward Pass</h3>

            <pre><code>// ... class TransformerBlock
    backward(outputGradients, learningRate) {
        // outputGradients: [seqLen][embeddingDim]
        const seqLen = outputGradients.length;

        // ====== Second residual backward ======
        // Output = postAttention + mlpOutput
        // Gradient flows to both paths
        const mlpOutputGrad = outputGradients;
        const postAttentionGrad1 = outputGradients;  // Direct path through residual

        // ====== MLP backward ======
        const normalized2Grad = this.mlp.backward(mlpOutputGrad, learningRate);
        const postAttentionGrad2 = this.layerNorm2.backward(normalized2Grad, learningRate);

        // Combine gradients at post-attention point
        const postAttentionGrad = new Array(seqLen);
        for (let t = 0; t < seqLen; t++) {
            postAttentionGrad[t] = new Array(this.embeddingDim);
            for (let d = 0; d < this.embeddingDim; d++) {
                postAttentionGrad[t][d] = postAttentionGrad1[t][d] + postAttentionGrad2[t][d];
            }
        }

        // ====== First residual backward ======
        // PostAttention = input + attended
        const attendedGrad = postAttentionGrad;
        const inputGrad1 = postAttentionGrad;  // Direct path through residual

        // ====== Attention backward ======
        const normalized1Grad = this.attention.backward(attendedGrad, learningRate);
        const inputGrad2 = this.layerNorm1.backward(normalized1Grad, learningRate);

        // Combine gradients at input point
        const inputGradients = new Array(seqLen);
        for (let t = 0; t < seqLen; t++) {
            inputGradients[t] = new Array(this.embeddingDim);
            for (let d = 0; d < this.embeddingDim; d++) {
                inputGradients[t][d] = inputGrad1[t][d] + inputGrad2[t][d];
            }
        }

        return inputGradients;
    }</code></pre>

            <p>
                The key insight in the backward pass is that residual connections split the gradient, it flows through both the transformation path (attention/MLP) and directly through the skip connection. At each residual point, we sum the gradients from both paths.
            </p>

            <p>This is why residual connections help with gradient flow: even if the attention or MLP gradients vanish, the direct path always carries the full gradient signal.</p>

            <h1>The Complete Model: ChatGPT</h1>

            <p>Now we can assemble all components into a complete GPT-style language model. The architecture stacks multiple transformer blocks between the embedding layer and output layer:</p>

            <pre><code>class ChatGPT {
    embedding = null;       // Positional + token embeddings
    blocks = null;          // Array of transformer blocks
    finalNorm = null;       // Final layer normalization
    output = null;          // Output projection to vocabulary

    vocabSize = 0;
    embeddingDim = 0;
    numBlocks = 0;

    constructor(vocabSize, embeddingDim, numHeads, numBlocks, maxSeqLength) {
        this.vocabSize = vocabSize;
        this.embeddingDim = embeddingDim;
        this.numBlocks = numBlocks;

        // Embedding layer (token + positional)
        this.embedding = new PositionalEmbeddingLayer(vocabSize, embeddingDim, maxSeqLength);

        // Stack of transformer blocks
        this.blocks = new Array(numBlocks);
        for (let i = 0; i < numBlocks; i++) {
            this.blocks[i] = new TransformerBlock(embeddingDim, numHeads);
        }

        // Final layer normalization (GPT-2 style)
        this.finalNorm = new LayerNormalization(embeddingDim);

        // Output projection to vocabulary
        this.output = new OutputLayer(embeddingDim, vocabSize);
    }
}</code></pre>

            <p><code>OutputLayer</code> projects hidden states to vocabulary size and applies softmax.</p>

            <h3>ChatGPT Forward Pass</h3>

            <pre><code>// ... class ChatGPT
    forward(inputTokens) {
        // inputTokens: array of token IDs

        // Embed tokens with positional information
        let hidden = this.embedding.forward(inputTokens);

        // Pass through each transformer block
        for (let i = 0; i < this.numBlocks; i++) {
            hidden = this.blocks[i].forward(hidden);
        }

        // Final normalization
        hidden = this.finalNorm.forward(hidden);

        // Project to vocabulary probabilities
        const probabilities = this.output.forward(hidden);

        return probabilities;  // [seqLen][vocabSize]
    }</code></pre>

            <p>embeddings &#8594; transformer blocks &#8594; normalization &#8594; output probabilities. Each transformer block refines the representation, with attention gathering context and MLP processing it.</p>

            <h3>ChatGPT Backward Pass</h3>

            <pre><code>// ... class ChatGPT
    backward(targetTokens, learningRate) {
        // Backward through output layer
        let gradients = this.output.backward(targetTokens, learningRate);

        // Backward through final normalization
        gradients = this.finalNorm.backward(gradients, learningRate);

        // Backward through transformer blocks (in reverse order)
        for (let i = this.numBlocks - 1; i >= 0; i--) {
            gradients = this.blocks[i].backward(gradients, learningRate);
        }

        // Backward through embeddings
        this.embedding.backward(gradients, learningRate);
    }</code></pre>

            <p>Backpropagation flows in reverse through the network. Each layer updates its own weights and passes gradients to the previous layer. The transformer blocks process in reverse order—last block first, first block last.</p>

            <h3>Training Method</h3>

            <pre><code>// ... class ChatGPT
    train(inputTokens, targetTokens, learningRate) {
        // Forward pass
        const predictions = this.forward(inputTokens);

        // Compute loss
        const loss = Loss.crossEntropy(predictions, targetTokens);

        // Backward pass
        this.backward(targetTokens, learningRate);

        return loss;
    }</code></pre>

            <p>Training follows the same pattern as ChatRNN: forward pass to get predictions, compute cross-entropy loss, backward pass to update weights. The <code>Loss.crossEntropy</code> function works unchanged.</p>

            <h3>Text Generation</h3>

            <pre><code>// ... class ChatGPT
    generate(startTokens, maxLength) {
        const generated = [];
        for (let i = 0; i < startTokens.length; i++) {
            generated.push(startTokens[i]);
        }

        for (let i = 0; i < maxLength; i++) {
            // Get predictions for current sequence
            const probs = this.forward(generated);
            const lastProbs = probs[probs.length - 1];

            // Sample next token from the probability distribution
            const nextToken = this.#sampleFromDistribution(lastProbs);
            generated.push(nextToken);
        }

        return generated;
    }

    #sampleFromDistribution(probs) {
        const random = Math.random();
        let cumulative = 0;

        for (let i = 0; i < probs.length; i++) {
            cumulative += probs[i];
            if (random < cumulative) {
                return i;
            }
        }

        return probs.length - 1;
    }</code></pre>

            <p>
                To generate text, run forward on the current sequence, get the probability distribution for the next token, sample from it, append the result, and repeat. The <code>#sampleFromDistribution</code> method performs weighted random selection—tokens with higher probability are more likely to be chosen.
            </p>

            <h1>Putting It All Together</h1>

            <p>Let's train a small transformer on some text. We'll use modest dimensions to keep training fast—this is meant to be a proof of concept you can run and experiment with.</p>

            <pre><code>// ==========================================
// Training a Mini ChatGPT
// ==========================================

// Training data - a small corpus of text
const trainingText = `
The cat sat on the mat. The dog sat on the log.
The cat chased the mouse. The dog chased the cat.
The mouse ran away. The cat ran after the mouse.
The dog watched the cat chase the mouse.
In the morning the sun rises in the east.
In the evening the sun sets in the west.
The birds sing in the morning. The owls hoot at night.
Stars twinkle in the night sky. The moon glows bright.
The quick brown fox jumps over the lazy dog.
The lazy dog sleeps all day. The quick fox hunts at night.
`;

// Create and train tokenizer
const tokenizer = new Tokenizer();
tokenizer.train(trainingText, 50);  // Small vocabulary for demo
const vocabSize = tokenizer.getVocabSize();
console.log(`Vocabulary size: ${vocabSize}`);

// Tokenize training data
const tokens = tokenizer.encode(trainingText);
console.log(`Training tokens: ${tokens.length}`);

// Model hyperparameters
const embeddingDim = 32;    // Small embedding dimension
const numHeads = 4;         // 4 attention heads (8 dims each)
const numBlocks = 2;        // 2 transformer blocks
const maxSeqLength = 64;    // Maximum sequence length

// Create model
const model = new ChatGPT(vocabSize, embeddingDim, numHeads, numBlocks, maxSeqLength);

// Count parameters
let totalParams = 0;
// Embedding: vocabSize * embeddingDim + maxSeqLength * embeddingDim
totalParams += vocabSize * embeddingDim + maxSeqLength * embeddingDim;
// Each transformer block: attention + MLP + layer norms
const attentionParams = 4 * embeddingDim * embeddingDim;  // Q, K, V, O projections
const mlpParams = 2 * embeddingDim * (4 * embeddingDim) + embeddingDim + 4 * embeddingDim;
const layerNormParams = 4 * embeddingDim;  // 2 norms * (gamma + beta)
totalParams += numBlocks * (attentionParams + mlpParams + layerNormParams);
// Output layer
totalParams += embeddingDim * vocabSize + vocabSize;
console.log(`Approximate parameters: ${totalParams.toLocaleString()}`);

// Training parameters
const learningRate = 0.01;
const epochs = 200;
const sequenceLength = 16;

// Training loop
console.log("\n=== Training ===");
for (let epoch = 0; epoch < epochs; epoch++) {
    let totalLoss = 0;
    let batchCount = 0;

    // Slide window across training data
    for (let start = 0; start < tokens.length - sequenceLength - 1; start += 8) {
        const inputTokens = tokens.slice(start, start + sequenceLength);
        const targetTokens = tokens.slice(start + 1, start + sequenceLength + 1);

        const loss = model.train(inputTokens, targetTokens, learningRate);
        totalLoss += loss;
        batchCount++;
    }

    if (epoch % 20 === 0) {
        const avgLoss = totalLoss / batchCount;
        console.log(`Epoch ${epoch}: Loss = ${avgLoss.toFixed(4)}`);

        // Generate sample
        const prompt = tokenizer.encode("The ");
        const generated = model.generate(prompt, 10);
        const text = tokenizer.decode(generated);
        console.log(`  Sample: "${text}"`);
    }
}

// Final generation
console.log("\n=== Generation Examples ===");
const prompts = ["The cat ", "In the ", "The quick "];
for (const promptText of prompts) {
    const prompt = tokenizer.encode(promptText);
    const generated = model.generate(prompt, 15);
    const text = tokenizer.decode(generated);
    console.log(`"${promptText}" &#8594; "${text}"`);
}</code></pre>

            <p>This creates a transformer with approximately 100,000 parameters—tiny by modern standards, but enough to learn patterns in our small training corpus.</p>

            <h2>What You Should See</h2>

            <p>When you run this code:</p>

            <ol>
                <li><strong>Loss should decrease</strong> from around 4-5 (random guessing) toward 1-2 (learning patterns)</li>
                <li><strong>Generated text should improve</strong> from random tokens to word fragments to coherent phrases</li>
                <li><strong>Training completes in minutes</strong> on a modern computer—attention is O(n&#178;) but with short sequences it's manageable</li>
            </ol>

            <p>The model won't produce Shakespeare, but it should learn basic patterns like "The cat..." often leading to animal actions, or "In the..." often leading to time words.</p>

            <h2>Temperature</h2>

            <p>
                Our <code>generate</code> function samples from the probability distribution, but we can control <em>how</em> we sample. Temperature is a parameter that controls the randomness of the output. It's applied before softmax in the output layer.
            </p>

            <p>
                The idea is simple: divide the logits (raw scores before softmax) by a temperature value. Low temperature makes the distribution sharper—the model becomes more confident and predictable. High temperature flattens the distribution—the model becomes more random and creative.
            </p>

            <pre><code>// In the OutputLayer class, modify forward to accept temperature:
forward(input, temperature = 1.0) {
    const logits = [];
    for (let i = 0; i < this.vocabSize; i++) {
        let sum = this.bias[i];
        for (let j = 0; j < this.inputDim; j++) {
            sum += input[j] * this.weights[j][i];
        }
        logits.push(sum / temperature);  // Divide by temperature
    }
    return this.#softmax(logits);
}</code></pre>

            <p>What happens at different temperatures:</p>

            <ul>
                <li><strong>Temperature = 1.0</strong>: Default behavior, unchanged probabilities</li>
                <li><strong>Temperature &lt; 1.0</strong>: Sharper distribution. At 0.5, differences between probabilities are amplified—high probability tokens become even more likely</li>
                <li><strong>Temperature &gt; 1.0</strong>: Flatter distribution. At 2.0, probabilities become more uniform—unlikely tokens get a better chance</li>
                <li><strong>Temperature → 0</strong>: Approaches greedy decoding—always picks the highest probability token</li>
                <li><strong>Temperature → ∞</strong>: Approaches uniform random—every token equally likely</li>
            </ul>

            <p>To use temperature during generation, pass it through the forward calls:</p>

            <pre><code>// ... class ChatGPT
    generate(startTokens, maxLength, temperature = 1.0) {
        const generated = [...startTokens];

        for (let i = 0; i < maxLength; i++) {
            const probs = this.forward(generated, temperature);
            const lastProbs = probs[probs.length - 1];
            const nextToken = this.#sampleFromDistribution(lastProbs);
            generated.push(nextToken);
        }

        return generated;
    }

    forward(tokens, temperature = 1.0) {
        // ... embedding and transformer blocks ...

        // Apply temperature in output layer
        const output = [];
        for (let t = 0; t < tokens.length; t++) {
            output.push(this.outputLayer.forward(blockOutput[t], temperature));
        }
        return output;
    }</code></pre>

            <p>
                In practice, values between 0.7 and 1.0 work well for most tasks. Lower temperatures (0.2–0.5) are good for factual, deterministic outputs. Higher temperatures (1.0–1.5) encourage more varied, creative text—but too high and the output becomes incoherent.
            </p>

            <!--h1>What's Next?</h1>

            <p><strong>Training improvements:</strong></p>
            <ul>
                <li><strong>Batch processing</strong>: Train on multiple sequences simultaneously for better GPU utilization</li>
                <li><strong>Adam optimizer</strong>: Adaptive learning rates per parameter, much faster than vanilla SGD</li>
                <li><strong>Learning rate scheduling</strong>: Warm up then decay the learning rate</li>
                <li><strong>Gradient clipping</strong>: Prevent exploding gradients</li>
            </ul>

            <p><strong>Architecture improvements:</strong></p>
            <ul>
                <li><strong>Dropout</strong>: Randomly zero activations during training to prevent overfitting</li>
                <li><strong>Tied embeddings</strong>: Share weights between input and output embeddings</li>
                <li><strong>Rotary Position Embeddings (RoPE)</strong>: Better position encoding for long sequences</li>
                <li><strong>Flash Attention</strong>: Memory-efficient attention computation</li>
            </ul>

            <p><strong>Scale:</strong></p>
            <ul>
                <li>Real models train on trillions of tokens</li>
                <li>Embedding dimensions of 4096+ with dozens of layers</li>
                <li>Thousands of GPUs training for months</li>
            </ul>

            <p>The principles remain the same though. It's still embeddings, attention, feed-forward networks, residual connections, and gradient descent. The complexity comes from scale and some optimization tricks.</p-->

            <h2>Resources</h2>

            <ul>
                <li><a href="https://gist.github.com/gszauer/edd25c24c675768dad1c72f23e3d3d50">Full source code listing</a></li>
                <li><a href="minigpt.html">Interactive trainer / demo</a></li>
            </ul>

        </article>
    </main>

    <!-- Footer -->
    <footer>
        <div class="container" style="display:flex; justify-content:space-between; align-items:center; flex-wrap:wrap; gap:8px;">
            <div>&copy; 2025 <a href="https://gabormakesgames.com/">Gabor Szauer</a></div>
            <div style="display:flex; gap:1rem;">
                <a href="https://github.com/gszauer/Gab">GitHub</a>
                <a href="https://bsky.app/profile/gszauer.bsky.social">bsky</a>
            </div>
        </div>
    </footer>

    <script>
        // JavaScript syntax highlighting with proper tokenization
        function highlightJavaScript() {
            // Get all code blocks except ASCII diagrams
            const codeBlocks = document.querySelectorAll('pre:not(.ascii-diagram) code');

            codeBlocks.forEach(block => {
                // Add language class
                block.classList.add('language-javascript');

                // Get the text content
                const code = block.textContent;

                // Tokenize the code
                const tokens = tokenizeJavaScript(code);

                // Build HTML from tokens
                let html = '';
                for (const token of tokens) {
                    if (token.type === 'plain') {
                        html += escapeHtml(token.value);
                    } else {
                        html += `<span class="${token.type}">${escapeHtml(token.value)}</span>`;
                    }
                }

                // Set the highlighted HTML
                block.innerHTML = html;
            });
        }

        function tokenizeJavaScript(code) {
            const tokens = [];
            let i = 0;

            while (i < code.length) {
                let matched = false;

                // Skip whitespace but preserve it
                if (/\s/.test(code[i])) {
                    let start = i;
                    while (i < code.length && /\s/.test(code[i])) i++;
                    tokens.push({ type: 'plain', value: code.substring(start, i) });
                    continue;
                }

                // Comments
                if (code[i] === '/' && i + 1 < code.length) {
                    if (code[i + 1] === '/') {
                        // Single line comment
                        let start = i;
                        i += 2;
                        while (i < code.length && code[i] !== '\n') i++;
                        tokens.push({ type: 'comment', value: code.substring(start, i) });
                        continue;
                    } else if (code[i + 1] === '*') {
                        // Multi-line comment
                        let start = i;
                        i += 2;
                        while (i + 1 < code.length && !(code[i] === '*' && code[i + 1] === '/')) i++;
                        if (i + 1 < code.length) i += 2;
                        tokens.push({ type: 'comment', value: code.substring(start, i) });
                        continue;
                    }
                }

                // Strings
                if (code[i] === '"' || code[i] === "'" || code[i] === '`') {
                    const quote = code[i];
                    let start = i;
                    i++;
                    while (i < code.length && code[i] !== quote) {
                        if (code[i] === '\\' && i + 1 < code.length) {
                            i += 2; // Skip escaped character
                        } else {
                            i++;
                        }
                    }
                    if (i < code.length) i++; // Include closing quote
                    tokens.push({ type: 'string', value: code.substring(start, i) });
                    continue;
                }

                // Numbers
                if (/\d/.test(code[i]) || (code[i] === '.' && i + 1 < code.length && /\d/.test(code[i + 1]))) {
                    let start = i;
                    while (i < code.length && /[\d.]/.test(code[i])) i++;
                    tokens.push({ type: 'number', value: code.substring(start, i) });
                    continue;
                }

                // Identifiers and keywords
                if (/[a-zA-Z_$]/.test(code[i])) {
                    let start = i;
                    while (i < code.length && /[a-zA-Z0-9_$]/.test(code[i])) i++;
                    const word = code.substring(start, i);

                    // Check if it's a keyword
                    const keywords = ['const', 'let', 'var', 'function', 'class', 'if', 'else', 'for', 'while', 'do',
                        'switch', 'case', 'break', 'continue', 'return', 'new', 'this', 'typeof', 'instanceof',
                        'try', 'catch', 'finally', 'throw', 'extends', 'implements', 'static', 'import', 'export',
                        'from', 'as', 'default', 'async', 'await', 'yield', 'of', 'in', 'debugger', 'with', 'delete', 'void'];

                    const booleans = ['true', 'false'];
                    const nullish = ['null', 'undefined'];

                    let type = 'plain';
                    if (keywords.includes(word)) {
                        type = 'keyword';
                    } else if (booleans.includes(word)) {
                        type = 'boolean';
                    } else if (word === 'null') {
                        type = 'null';
                    } else if (word === 'undefined') {
                        type = 'undefined';
                    } else {
                        // Check if it's a function call (followed by parenthesis)
                        let j = i;
                        while (j < code.length && /\s/.test(code[j])) j++;
                        if (j < code.length && code[j] === '(') {
                            type = 'function';
                        } else if (word[0] === word[0].toUpperCase() && word[0] !== word[0].toLowerCase()) {
                            // Check if previous token was 'new', 'class', or 'extends' keyword
                            let prevToken = tokens[tokens.length - 1];
                            while (prevToken && prevToken.type === 'plain' && prevToken.value.trim() === '') {
                                prevToken = tokens[tokens.length - 2];
                            }
                            if (prevToken && prevToken.type === 'keyword' &&
                                ['new', 'class', 'extends'].includes(prevToken.value)) {
                                type = 'class-name';
                            }
                        }
                    }

                    tokens.push({ type, value: word });
                    continue;
                }

                // Operators and punctuation
                const operators = [
                    '===', '!==', '==', '!=', '<=', '>=', '<<', '>>', '>>>', '+=', '-=', '*=', '/=', '%=',
                    '++', '--', '&&', '||', '<', '>', '+', '-', '*', '/', '%', '=', '!', '?', ':', '&', '|', '^', '~'
                ];

                // Try to match multi-character operators first
                let operatorMatched = false;
                for (let len = 3; len >= 1; len--) {
                    const potential = code.substring(i, i + len);
                    if (operators.includes(potential)) {
                        tokens.push({ type: 'operator', value: potential });
                        i += len;
                        operatorMatched = true;
                        break;
                    }
                }

                if (operatorMatched) continue;

                // Punctuation
                if (/[{}()\[\];,.]/.test(code[i])) {
                    tokens.push({ type: 'punctuation', value: code[i] });
                    i++;
                    continue;
                }

                // Default: treat as plain text
                tokens.push({ type: 'plain', value: code[i] });
                i++;
            }

            return tokens;
        }

        function escapeHtml(text) {
            const div = document.createElement('div');
            div.textContent = text;
            return div.innerHTML;
        }

        // Run highlighting when page loads
        document.addEventListener('DOMContentLoaded', () => {
            highlightJavaScript();
            drawTransformerPipelineDiagram();
            drawPositionalEmbeddingDiagram();
            drawLayerNormDiagram();
            drawCausalMaskDiagram();
            drawMlpBlockDiagram();
            drawTransformerBlockDiagram();
        });

        const diagramPalette = {
            background: '#0a0a14',
            panel: '#12121c',
            accent: '#ff2e88',
            accentSoft: '#ff86c3',
            text: '#e9e9f2',
            muted: '#a5a7bf',
            line: '#2a2a3a'
        };

        function setupCanvas(canvas) {
            const dpr = window.devicePixelRatio || 1;
            const logicalWidth = parseInt(canvas.getAttribute('width'), 10);
            const logicalHeight = parseInt(canvas.getAttribute('height'), 10);
            canvas.width = logicalWidth * dpr;
            canvas.height = logicalHeight * dpr;
            const ctx = canvas.getContext('2d');
            ctx.setTransform(dpr, 0, 0, dpr, 0, 0);
            canvas.style.width = logicalWidth + 'px';
            canvas.style.height = logicalHeight + 'px';
            canvas.style.maxWidth = '100%';
            canvas.style.height = 'auto';
            return { ctx, width: logicalWidth, height: logicalHeight };
        }

        function drawRoundedRect(ctx, x, y, width, height, radius, fillStyle, strokeStyle) {
            const r = Math.min(radius, width / 2, height / 2);
            ctx.beginPath();
            ctx.moveTo(x + r, y);
            ctx.lineTo(x + width - r, y);
            ctx.quadraticCurveTo(x + width, y, x + width, y + r);
            ctx.lineTo(x + width, y + height - r);
            ctx.quadraticCurveTo(x + width, y + height, x + width - r, y + height);
            ctx.lineTo(x + r, y + height);
            ctx.quadraticCurveTo(x, y + height, x, y + height - r);
            ctx.lineTo(x, y + r);
            ctx.quadraticCurveTo(x, y, x + r, y);
            ctx.closePath();
            if (fillStyle) {
                ctx.fillStyle = fillStyle;
                ctx.fill();
            }
            if (strokeStyle) {
                ctx.strokeStyle = strokeStyle;
                ctx.stroke();
            }
        }

        function drawArrow(ctx, fromX, fromY, toX, toY, color = diagramPalette.accentSoft, lineWidth = 2) {
            ctx.save();
            ctx.strokeStyle = color;
            ctx.lineWidth = lineWidth;
            ctx.beginPath();
            ctx.moveTo(fromX, fromY);
            ctx.lineTo(toX, toY);
            ctx.stroke();

            const angle = Math.atan2(toY - fromY, toX - fromX);
            const headLength = 10;
            ctx.beginPath();
            ctx.moveTo(toX, toY);
            ctx.lineTo(
                toX - headLength * Math.cos(angle - Math.PI / 6),
                toY - headLength * Math.sin(angle - Math.PI / 6)
            );
            ctx.lineTo(
                toX - headLength * Math.cos(angle + Math.PI / 6),
                toY - headLength * Math.sin(angle + Math.PI / 6)
            );
            ctx.closePath();
            ctx.fillStyle = color;
            ctx.fill();
            ctx.restore();
        }

        function drawTransformerPipelineDiagram() {
            const canvas = document.getElementById('transformerPipelineDiagram');
            if (!canvas) return;

            const { ctx, width, height } = setupCanvas(canvas);
            ctx.clearRect(0, 0, width, height);
            ctx.fillStyle = diagramPalette.background;
            ctx.fillRect(0, 0, width, height);

            // Top row stages
            const stages = [
                { title: 'Token IDs', bottom: '[42, 17, 8]' },
                { title: 'Embeddings', bottom: 'Token + Positional' },
                { title: 'Transformer', bottom: 'Blocks' },
                { title: 'Output', bottom: 'Next-token logits' },
                { title: 'Probabilities', bottom: 'Softmax output' }
            ];

            ctx.textAlign = 'center';
            const boxWidth = 150;
            const boxHeight = 50;
            const gap = 20;
            const totalWidth = stages.length * boxWidth + (stages.length - 1) * gap;
            const startX = (width - totalWidth) / 2;
            const labelSpacing = 16;
            const topRowY = 30;

            // Draw top row boxes
            stages.forEach((stage, index) => {
                const x = startX + index * (boxWidth + gap);
                drawRoundedRect(ctx, x, topRowY, boxWidth, boxHeight, 10, diagramPalette.panel, diagramPalette.line);

                ctx.fillStyle = diagramPalette.text;
                ctx.font = 'bold 14px ui-sans-serif, system-ui, -apple-system, "Segoe UI", sans-serif';
                ctx.fillText(stage.title, x + boxWidth / 2, topRowY + boxHeight / 2 + 5);

                ctx.fillStyle = diagramPalette.muted;
                const isIds = stage.bottom.startsWith('[');
                ctx.font = isIds
                    ? '12px ui-monospace, SFMono-Regular, Menlo, monospace'
                    : '11px ui-sans-serif, system-ui, -apple-system, "Segoe UI", sans-serif';
                ctx.fillText(stage.bottom, x + boxWidth / 2, topRowY + boxHeight + labelSpacing);

                // Draw arrow to next box
                if (index < stages.length - 1) {
                    const nextX = x + boxWidth + gap;
                    drawArrow(ctx, x + boxWidth + 2, topRowY + boxHeight / 2, nextX - 2, topRowY + boxHeight / 2);
                }
            });

            // Draw downward arrow from Transformer Blocks
            const transformerX = startX + 2 * (boxWidth + gap);
            const arrowStartY = topRowY + boxHeight + labelSpacing + 10;
            const detailBoxY = arrowStartY + 35;
            drawArrow(ctx, transformerX + boxWidth / 2, arrowStartY, transformerX + boxWidth / 2, detailBoxY - 5);

            // Detail box for transformer blocks
            const detailBoxWidth = 160;
            const detailBoxHeight = 120;
            const detailBoxX = transformerX + boxWidth / 2 - detailBoxWidth / 2;

            drawRoundedRect(ctx, detailBoxX, detailBoxY, detailBoxWidth, detailBoxHeight, 10, '#171726', diagramPalette.line);

            // Draw detail box content
            ctx.fillStyle = diagramPalette.text;
            ctx.font = 'bold 13px ui-sans-serif, system-ui, -apple-system, "Segoe UI", sans-serif';
            ctx.fillText('\u00d7 N Blocks:', detailBoxX + detailBoxWidth / 2, detailBoxY + 22);

            const items = ['LayerNorm', 'Attention', 'LayerNorm', 'MLP', 'Residuals'];
            ctx.font = '12px ui-sans-serif, system-ui, -apple-system, "Segoe UI", sans-serif';
            ctx.fillStyle = diagramPalette.muted;
            items.forEach((item, i) => {
                ctx.fillText('- ' + item, detailBoxX + detailBoxWidth / 2, detailBoxY + 42 + i * 16);
            });
        }

        function drawPositionalEmbeddingDiagram() {
            const canvas = document.getElementById('positionalEmbeddingDiagram');
            if (!canvas) return;

            const { ctx, width, height } = setupCanvas(canvas);
            ctx.clearRect(0, 0, width, height);
            ctx.fillStyle = diagramPalette.background;
            ctx.fillRect(0, 0, width, height);

            const tokens = [
                { token: '"The"', tokenEmbed: ['0.12', '-0.34', '...'], posEmbed: ['0.01', '0.02', '...'], final: ['0.13', '-0.32', '...'] },
                { token: '"cat"', tokenEmbed: ['0.45', '0.67', '...'], posEmbed: ['0.08', '-0.03', '...'], final: ['0.53', '0.64', '...'] },
                { token: '"sat"', tokenEmbed: ['0.23', '-0.89', '...'], posEmbed: ['0.15', '0.11', '...'], final: ['0.38', '-0.78', '...'] }
            ];

            const colWidth = 150;
            const totalWidth = tokens.length * colWidth;
            const startX = 100;
            const labelX = 80;

            ctx.textAlign = 'center';

            // Row positions
            const tokenRowY = 30;
            const tokenEmbedY = 80;
            const plusY = 145;
            const posEmbedY = 190;
            const equalsY = 255;
            const finalY = 295;

            // Draw each column
            tokens.forEach((col, i) => {
                const x = startX + i * colWidth + colWidth / 2;

                // Token name
                ctx.fillStyle = diagramPalette.text;
                ctx.font = 'bold 14px ui-monospace, SFMono-Regular, Menlo, monospace';
                ctx.fillText(col.token, x, tokenRowY);

                // Arrow down
                drawArrow(ctx, x, tokenRowY + 10, x, tokenEmbedY - 20);

                // Token embedding values
                ctx.fillStyle = diagramPalette.muted;
                ctx.font = '13px ui-monospace, SFMono-Regular, Menlo, monospace';
                ctx.fillText('[' + col.tokenEmbed[0] + ',', x, tokenEmbedY);
                ctx.fillText(col.tokenEmbed[1] + ',', x, tokenEmbedY + 18);
                ctx.fillText(col.tokenEmbed[2] + ']', x, tokenEmbedY + 36);

                // Plus sign
                ctx.fillStyle = diagramPalette.accentSoft;
                ctx.font = 'bold 18px ui-sans-serif, system-ui, sans-serif';
                ctx.fillText('+', x, plusY);

                // Position embedding values
                ctx.fillStyle = diagramPalette.muted;
                ctx.font = '13px ui-monospace, SFMono-Regular, Menlo, monospace';
                ctx.fillText('[' + col.posEmbed[0] + ',', x, posEmbedY);
                ctx.fillText(col.posEmbed[1] + ',', x, posEmbedY + 18);
                ctx.fillText(col.posEmbed[2] + ']', x, posEmbedY + 36);

                // Equals sign
                ctx.fillStyle = diagramPalette.accentSoft;
                ctx.font = 'bold 18px ui-sans-serif, system-ui, sans-serif';
                ctx.fillText('=', x, equalsY);

                // Final values
                ctx.fillStyle = diagramPalette.text;
                ctx.font = '13px ui-monospace, SFMono-Regular, Menlo, monospace';
                ctx.fillText('[' + col.final[0] + ',', x, finalY);
                ctx.fillText(col.final[1] + ',', x, finalY + 18);
                ctx.fillText(col.final[2] + ']', x, finalY + 36);
            });

            // Draw row labels on the left
            ctx.textAlign = 'right';
            ctx.fillStyle = diagramPalette.text;
            ctx.font = '12px ui-sans-serif, system-ui, -apple-system, "Segoe UI", sans-serif';
            ctx.fillText('Token:', labelX, tokenRowY);
            ctx.fillText('Token', labelX, tokenEmbedY);
            ctx.fillText('Embed:', labelX, tokenEmbedY + 18);
            ctx.fillText('Position', labelX, posEmbedY);
            ctx.fillText('Embed:', labelX, posEmbedY + 18);
            ctx.fillText('Final:', labelX, finalY + 18);

            // "Different for each position" annotation with graphical arrow
            const lastColX = startX + 2 * colWidth + colWidth / 2;
            const annotationX = lastColX + 50;
            const annotationY = posEmbedY + 18;

            // Draw arrow pointing left
            drawArrow(ctx, annotationX + 80, annotationY - 4, annotationX, annotationY - 4, diagramPalette.muted, 1.5);

            // Draw text after arrow
            ctx.textAlign = 'left';
            ctx.fillStyle = diagramPalette.muted;
            ctx.font = 'italic 11px ui-sans-serif, system-ui, -apple-system, "Segoe UI", sans-serif';
            ctx.fillText('Different for each position', annotationX + 90, annotationY);
        }

        function drawLayerNormDiagram() {
            const canvas = document.getElementById('layerNormDiagram');
            if (!canvas) return;

            const { ctx, width, height } = setupCanvas(canvas);
            ctx.clearRect(0, 0, width, height);
            ctx.fillStyle = diagramPalette.background;
            ctx.fillRect(0, 0, width, height);

            const centerX = width / 2;
            const labelX = 200;

            // Row positions
            let y = 28;

            // Input
            ctx.fillStyle = diagramPalette.text;
            ctx.font = '13px ui-sans-serif, system-ui, -apple-system, "Segoe UI", sans-serif';
            ctx.textAlign = 'right';
            ctx.fillText('Input:', labelX, y);
            ctx.textAlign = 'center';
            ctx.fillStyle = diagramPalette.muted;
            ctx.font = '14px ui-monospace, SFMono-Regular, Menlo, monospace';
            ctx.fillText('[2.0, -1.0, 4.0, 1.0]', centerX + 50, y);

            // Arrow down
            drawArrow(ctx, centerX, y + 12, centerX, y + 38);
            y += 60;

            // Mean and Variance calculation
            ctx.fillStyle = diagramPalette.text;
            ctx.font = '13px ui-sans-serif, system-ui, -apple-system, "Segoe UI", sans-serif';
            ctx.textAlign = 'right';
            ctx.fillText('Mean:', labelX, y);
            ctx.textAlign = 'center';
            ctx.font = '13px ui-monospace, SFMono-Regular, Menlo, monospace';
            ctx.fillText('(2 + -1 + 4 + 1) / 4 = 1.5', centerX + 50, y);
            y += 22;
            ctx.fillStyle = diagramPalette.text;
            ctx.font = '13px ui-sans-serif, system-ui, -apple-system, "Segoe UI", sans-serif';
            ctx.textAlign = 'right';
            ctx.fillText('Var:', labelX, y);
            ctx.textAlign = 'center';
            ctx.font = '13px ui-monospace, SFMono-Regular, Menlo, monospace';
            ctx.fillText('average of squared deviations = 3.25', centerX + 50, y);

            // Arrow down
            drawArrow(ctx, centerX, y + 12, centerX, y + 38);
            y += 60;

            // Normalized formula
            ctx.fillStyle = diagramPalette.text;
            ctx.font = '13px ui-sans-serif, system-ui, -apple-system, "Segoe UI", sans-serif';
            ctx.textAlign = 'right';
            ctx.fillText('Normalized:', labelX, y);
            ctx.textAlign = 'center';
            ctx.fillStyle = diagramPalette.muted;
            ctx.font = '12px ui-monospace, SFMono-Regular, Menlo, monospace';
            ctx.fillText('[(2-1.5)/\u221a3.25, (-1-1.5)/\u221a3.25, ...]', centerX + 50, y);
            y += 20;

            // Normalized result
            ctx.fillStyle = diagramPalette.text;
            ctx.font = '14px ui-monospace, SFMono-Regular, Menlo, monospace';
            ctx.fillText('= [0.28, -1.39, 1.39, -0.28]', centerX + 50, y);

            // Arrow down
            drawArrow(ctx, centerX, y + 12, centerX, y + 38);
            y += 60;

            // Output
            ctx.fillStyle = diagramPalette.text;
            ctx.font = '13px ui-sans-serif, system-ui, -apple-system, "Segoe UI", sans-serif';
            ctx.textAlign = 'right';
            ctx.fillText('Output:', labelX, y);
            ctx.textAlign = 'center';
            ctx.fillStyle = diagramPalette.accentSoft;
            ctx.font = '14px ui-monospace, SFMono-Regular, Menlo, monospace';
            ctx.fillText('gamma * normalized + beta', centerX + 50, y);
            ctx.fillStyle = diagramPalette.muted;
            ctx.font = '12px ui-sans-serif, system-ui, -apple-system, "Segoe UI", sans-serif';
            ctx.fillText('(elementwise)', centerX + 50, y + 20);
        }

        function drawCausalMaskDiagram() {
            const canvas = document.getElementById('causalMaskDiagram');
            if (!canvas) return;

            const { ctx, width, height } = setupCanvas(canvas);
            ctx.clearRect(0, 0, width, height);
            ctx.fillStyle = diagramPalette.background;
            ctx.fillRect(0, 0, width, height);

            const tokens = ['"The"', '"cat"', '"sat"', '"on"'];
            const positions = ['0', '1', '2', '3'];
            const descriptions = [
                'Can only see itself',
                'Can see "The" and itself',
                'Can see "The", "cat", itself',
                'Can see everything before'
            ];

            const cellSize = 50;
            const gridStartX = 200;
            const gridStartY = 70;
            const rowLabelX = 30;

            // Header: "Positions being looked at:"
            ctx.fillStyle = diagramPalette.text;
            ctx.font = '13px ui-sans-serif, system-ui, -apple-system, "Segoe UI", sans-serif';
            ctx.textAlign = 'center';
            ctx.fillText('Positions being looked at:', gridStartX + (cellSize * 2), 20);

            // Column headers (position numbers and tokens)
            for (let i = 0; i < 4; i++) {
                const x = gridStartX + i * cellSize + cellSize / 2;
                ctx.fillStyle = diagramPalette.muted;
                ctx.font = '12px ui-monospace, SFMono-Regular, Menlo, monospace';
                ctx.fillText(positions[i], x, 40);
                ctx.fillStyle = diagramPalette.text;
                ctx.font = '12px ui-monospace, SFMono-Regular, Menlo, monospace';
                ctx.fillText(tokens[i], x, 56);
            }

            // Draw grid border
            const gridWidth = cellSize * 4;
            const gridHeight = cellSize * 4;
            drawRoundedRect(ctx, gridStartX, gridStartY, gridWidth, gridHeight, 8, null, diagramPalette.line);

            // Draw rows
            for (let row = 0; row < 4; row++) {
                const y = gridStartY + row * cellSize;

                // Row label
                ctx.fillStyle = diagramPalette.muted;
                ctx.font = '11px ui-sans-serif, system-ui, -apple-system, "Segoe UI", sans-serif';
                ctx.textAlign = 'right';
                ctx.fillText('Position ' + row, rowLabelX + 60, y + cellSize / 2 - 6);
                ctx.fillStyle = diagramPalette.text;
                ctx.font = '12px ui-monospace, SFMono-Regular, Menlo, monospace';
                ctx.fillText(tokens[row], rowLabelX + 60, y + cellSize / 2 + 10);

                // Draw cells
                for (let col = 0; col < 4; col++) {
                    const x = gridStartX + col * cellSize;
                    const canSee = col <= row;

                    // Cell background
                    ctx.fillStyle = canSee ? 'rgba(80, 250, 123, 0.15)' : 'rgba(255, 46, 136, 0.1)';
                    ctx.fillRect(x + 1, y + 1, cellSize - 2, cellSize - 2);

                    // Check or X
                    ctx.textAlign = 'center';
                    ctx.font = '18px ui-sans-serif, system-ui, sans-serif';
                    ctx.fillStyle = canSee ? '#50fa7b' : '#ff5555';
                    ctx.fillText(canSee ? '\u2713' : '\u2717', x + cellSize / 2, y + cellSize / 2 + 6);
                }

                // Draw grid lines
                if (row > 0) {
                    ctx.strokeStyle = diagramPalette.line;
                    ctx.beginPath();
                    ctx.moveTo(gridStartX, y);
                    ctx.lineTo(gridStartX + gridWidth, y);
                    ctx.stroke();
                }

                // Description on right
                ctx.fillStyle = diagramPalette.muted;
                ctx.font = '11px ui-sans-serif, system-ui, -apple-system, "Segoe UI", sans-serif';
                ctx.textAlign = 'left';
                ctx.fillText(descriptions[row], gridStartX + gridWidth + 15, y + cellSize / 2 + 4);
            }

            // Draw vertical grid lines
            for (let col = 1; col < 4; col++) {
                const x = gridStartX + col * cellSize;
                ctx.strokeStyle = diagramPalette.line;
                ctx.beginPath();
                ctx.moveTo(x, gridStartY);
                ctx.lineTo(x, gridStartY + gridHeight);
                ctx.stroke();
            }
        }

        function drawMlpBlockDiagram() {
            const canvas = document.getElementById('mlpBlockDiagram');
            if (!canvas) return;

            const { ctx, width, height } = setupCanvas(canvas);
            ctx.clearRect(0, 0, width, height);
            ctx.fillStyle = diagramPalette.background;
            ctx.fillRect(0, 0, width, height);

            // Draw outer box
            const boxPadding = 20;
            const outerBoxX = 30;
            const outerBoxY = 15;
            const outerBoxWidth = width - 60;
            const outerBoxHeight = height - 30;
            drawRoundedRect(ctx, outerBoxX, outerBoxY, outerBoxWidth, outerBoxHeight, 12, diagramPalette.panel, diagramPalette.line);

            // Title
            ctx.fillStyle = diagramPalette.text;
            ctx.font = 'bold 14px ui-sans-serif, system-ui, -apple-system, "Segoe UI", sans-serif';
            ctx.textAlign = 'center';
            ctx.fillText('MLP Block', width / 2, 38);

            // Flow stages
            const stages = [
                { name: 'Input', dim: '[64]' },
                { name: 'Dense1', dim: '[256]' },
                { name: 'GELU', dim: '[256]' },
                { name: 'Dense2', dim: '[64]' },
                { name: 'Output', dim: '[64]' }
            ];

            const stageY = 75;
            const boxWidth = 80;
            const boxHeight = 36;
            const gap = 50;
            const totalWidth = stages.length * boxWidth + (stages.length - 1) * gap;
            const startX = (width - totalWidth) / 2;

            stages.forEach((stage, i) => {
                const x = startX + i * (boxWidth + gap);

                // Stage box
                drawRoundedRect(ctx, x, stageY, boxWidth, boxHeight, 8, '#171726', diagramPalette.line);

                // Stage name
                ctx.fillStyle = diagramPalette.text;
                ctx.font = '13px ui-sans-serif, system-ui, -apple-system, "Segoe UI", sans-serif';
                ctx.textAlign = 'center';
                ctx.fillText(stage.name, x + boxWidth / 2, stageY + boxHeight / 2 + 5);

                // Dimension below
                ctx.fillStyle = diagramPalette.muted;
                ctx.font = '11px ui-monospace, SFMono-Regular, Menlo, monospace';
                ctx.fillText(stage.dim, x + boxWidth / 2, stageY + boxHeight + 14);

                // Arrow to next
                if (i < stages.length - 1) {
                    drawArrow(ctx, x + boxWidth + 5, stageY + boxHeight / 2, x + boxWidth + gap - 5, stageY + boxHeight / 2);
                }
            });

            // Bottom label
            ctx.fillStyle = diagramPalette.muted;
            ctx.font = '12px ui-sans-serif, system-ui, -apple-system, "Segoe UI", sans-serif';
            ctx.textAlign = 'center';
            ctx.fillText('embeddingDim  \u2192  4\u00d7embeddingDim  \u2192  embeddingDim', width / 2, height - 18);
        }

        function drawTransformerBlockDiagram() {
            const canvas = document.getElementById('transformerBlockDiagram');
            if (!canvas) return;

            const { ctx, width, height } = setupCanvas(canvas);
            ctx.clearRect(0, 0, width, height);
            ctx.fillStyle = diagramPalette.background;
            ctx.fillRect(0, 0, width, height);

            // Draw outer box
            const outerBoxX = 20;
            const outerBoxY = 10;
            const outerBoxWidth = width - 40;
            const outerBoxHeight = height - 20;
            drawRoundedRect(ctx, outerBoxX, outerBoxY, outerBoxWidth, outerBoxHeight, 12, diagramPalette.panel, diagramPalette.line);

            // Title
            ctx.fillStyle = diagramPalette.text;
            ctx.font = 'bold 14px ui-sans-serif, system-ui, -apple-system, "Segoe UI", sans-serif';
            ctx.textAlign = 'center';
            ctx.fillText('Transformer Block', width / 2, 32);

            // Flow stages
            const stages = ['Input', 'LayerNorm', 'Attention', 'LayerNorm', 'MLP', 'Output'];
            const mainY = 70;
            const boxWidth = 85;
            const boxHeight = 32;
            const gap = 45;
            const totalWidth = stages.length * boxWidth + (stages.length - 1) * gap;
            const startX = (width - totalWidth) / 2;

            // Store positions for residual connections
            const positions = [];

            stages.forEach((stage, i) => {
                const x = startX + i * (boxWidth + gap);
                positions.push({ x, centerX: x + boxWidth / 2 });

                // Stage box
                drawRoundedRect(ctx, x, mainY, boxWidth, boxHeight, 6, '#171726', diagramPalette.line);

                // Stage name
                ctx.fillStyle = diagramPalette.text;
                ctx.font = '12px ui-sans-serif, system-ui, -apple-system, "Segoe UI", sans-serif';
                ctx.textAlign = 'center';
                ctx.fillText(stage, x + boxWidth / 2, mainY + boxHeight / 2 + 4);

                // Arrow to next (with split for residuals)
                if (i < stages.length - 1) {
                    const arrowStartX = x + boxWidth + 3;
                    const arrowEndX = x + boxWidth + gap - 3;

                    // For Input->LayerNorm and after Attention, show split
                    if (i === 0 || i === 2) {
                        // Draw line down then right
                        const splitX = arrowStartX + 8;
                        ctx.strokeStyle = diagramPalette.accentSoft;
                        ctx.lineWidth = 2;
                        ctx.beginPath();
                        ctx.moveTo(arrowStartX, mainY + boxHeight / 2);
                        ctx.lineTo(splitX, mainY + boxHeight / 2);
                        ctx.stroke();

                        // Vertical line down
                        ctx.beginPath();
                        ctx.moveTo(splitX, mainY + boxHeight / 2);
                        ctx.lineTo(splitX, mainY + boxHeight + 35);
                        ctx.stroke();

                        // Continue arrow
                        drawArrow(ctx, splitX, mainY + boxHeight / 2, arrowEndX, mainY + boxHeight / 2);
                    } else if (i === 1 || i === 3) {
                        // After LayerNorm or second LayerNorm - show merge with +
                        const mergeX = arrowStartX + gap - 20;

                        // Draw arrow
                        drawArrow(ctx, arrowStartX, mainY + boxHeight / 2, arrowEndX, mainY + boxHeight / 2);

                        // Draw + circle
                        const plusX = (arrowStartX + arrowEndX) / 2;
                        ctx.beginPath();
                        ctx.arc(plusX, mainY + boxHeight / 2, 10, 0, Math.PI * 2);
                        ctx.fillStyle = diagramPalette.panel;
                        ctx.fill();
                        ctx.strokeStyle = diagramPalette.accentSoft;
                        ctx.lineWidth = 1.5;
                        ctx.stroke();

                        ctx.fillStyle = diagramPalette.accentSoft;
                        ctx.font = 'bold 14px ui-sans-serif, system-ui, sans-serif';
                        ctx.fillText('+', plusX, mainY + boxHeight / 2 + 5);

                        // Residual line coming up
                        ctx.strokeStyle = diagramPalette.accentSoft;
                        ctx.lineWidth = 2;
                        ctx.beginPath();
                        ctx.moveTo(plusX, mainY + boxHeight / 2 + 10);
                        ctx.lineTo(plusX, mainY + boxHeight + 35);
                        ctx.stroke();

                        // Horizontal line from previous split
                        const prevSplitX = positions[i - 1].x + boxWidth + 11;
                        ctx.beginPath();
                        ctx.moveTo(prevSplitX, mainY + boxHeight + 35);
                        ctx.lineTo(plusX, mainY + boxHeight + 35);
                        ctx.stroke();

                        // Residual label
                        ctx.fillStyle = diagramPalette.muted;
                        ctx.font = '10px ui-sans-serif, system-ui, -apple-system, "Segoe UI", sans-serif';
                        ctx.fillText('(residual)', (prevSplitX + plusX) / 2, mainY + boxHeight + 50);
                    } else {
                        drawArrow(ctx, arrowStartX, mainY + boxHeight / 2, arrowEndX, mainY + boxHeight / 2);
                    }
                }
            });
        }
    </script>
</body>
</html>
